{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5103)\n",
      "/home/ubuntu/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages/theano/sandbox/cuda/__init__.py:601: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/preprocessed_data/tips_10-10-20_1.00-1.00-1.00/\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from __future__ import division\n",
    "import joblib\n",
    "import glob\n",
    "import os, re\n",
    "import numpy as np\n",
    "import nrrd\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics, decomposition\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "from joblib import Parallel, delayed  \n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "USERPATH = os.path.expanduser(\"~\")\n",
    "print(USERPATH)\n",
    "import six.moves.cPickle as pickle\n",
    "# import tensorflow as tf\n",
    "\n",
    "# import theano\n",
    "# theano.config.device = 'gpu'\n",
    "# theano.config.floatX = 'float32'\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# server = tf.train.Server.create_local_server()\n",
    "# sess = tf.Session(server.target)\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(sess)\n",
    "\n",
    "# tb = TensorBoard(log_dir='/tmp/tensorboard', histogram_freq=1, write_graph=True)\n",
    "\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# checkpointer = ModelCheckpoint(filepath=\"weights2d.hdf5\", verbose=1, save_best_only=True)\n",
    "patchsize = [10,10,20]\n",
    "data_spacing = [1,1,1]\n",
    "notipsPath = USERPATH + \"/preprocessed_data/notips_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "tipsPath = USERPATH + \"/preprocessed_data/tips_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "\n",
    "casesToExclude = [64,77]\n",
    "\n",
    "\n",
    "def getTrainingPaths(tipsPath, cases=[64,77]):\n",
    "    strL = \"\"\n",
    "    for c in cases:\n",
    "        strL+=\"%03d|\"%c\n",
    "    fnames=glob.glob(tipsPath + \"/*/*.nrrd\")\n",
    "    regex=re.compile(\"^((?!%s).)*$\"%strL[:-1])\n",
    "    paths = [m.group(0) for l in fnames for m in [regex.search(l)] if m]\n",
    "    return paths\n",
    "\n",
    "def loadAllDataFromPath(path, casesToExclude):\n",
    "    # path in directorty\n",
    "    \n",
    "#     cubeTipsPath = glob.glob(path + \"/*/*.nrrd\")\n",
    "    cubeTipsPath = getTrainingPaths(path, casesToExclude)\n",
    "    # number of samples\n",
    "    N = len(cubeTipsPath)\n",
    "    \n",
    "    cubeTips = []\n",
    "    data = []\n",
    "    for path_i in cubeTipsPath:\n",
    "        cubeTips.append(nrrd.read(path_i))\n",
    "    for i in range(N):\n",
    "        # c = np.array(cubeTips[i][0])  # for patches of size 20,20,20\n",
    "        c = np.array(cubeTips[i][0][:,:,:]) # for patches of size 10,10,10\n",
    "        if c.shape==tuple(patchsize):\n",
    "            data.append(np.array(c))\n",
    "    output = np.array(data, dtype='float32')\n",
    "    print('number of sample %d' %len(output))\n",
    "    return output\n",
    "\n",
    "\n",
    "print(tipsPath)\n",
    "# tips = loadAllDataFromPath(tipsPath, casesToExclude)\n",
    "# notips = loadAllDataFromPath(notipsPath, casesToExclude)[:3*len(tips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sample 590\n",
      "number of sample 9400\n",
      "590 2950\n",
      "target shape: (3540,)\n",
      "data shape: (3540, 10, 10, 20)\n"
     ]
    }
   ],
   "source": [
    "tips = loadAllDataFromPath(tipsPath, casesToExclude)\n",
    "notips = loadAllDataFromPath(notipsPath, casesToExclude)[:5*len(tips)]\n",
    "\n",
    "print(len(tips), len(notips))\n",
    "\n",
    "target_0 = [0 for i in range(len(notips))]\n",
    "target_1 = [1 for i in range(len(tips))]\n",
    "y_train = np.array(target_0 + target_1)\n",
    "print('target shape:', y_train.shape)\n",
    "X_train = np.array(list(notips)+list(tips))\n",
    "\n",
    "print('data shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape and label shape\n",
      "(3540, 10, 10, 20) (3540,)\n"
     ]
    }
   ],
   "source": [
    "o = 9\n",
    "f_Xtrain = open('X_data_n%d.save'%o, 'wb')\n",
    "f_ytrain = open('y_data_n%d.save'%o, 'wb')\n",
    "\n",
    "pickle.dump(X_train, f_Xtrain, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(y_train, f_ytrain, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "f_Xtrain.close()\n",
    "f_ytrain.close()\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "# Load the dataset\n",
    "f_Xdata = open('X_data_n%d.save'%o, 'rb')\n",
    "f_ydata = open('y_data_n%d.save'%o, 'rb')\n",
    "\n",
    "X_data_ = pickle.load(f_Xdata)\n",
    "X_data_ = X_data_.astype('float32')\n",
    "\n",
    "# normalize the raw data\n",
    "X_data_ -= np.mean(X_data_)\n",
    "X_data_ /= np.std(X_data_)\n",
    "\n",
    "## second method for normalization\n",
    "# X_data /= 255\n",
    "\n",
    "y_data= pickle.load(f_ydata)\n",
    "y_data_binary = to_categorical(y_data)\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_data)\n",
    "y_data = encoder.transform(y_data)\n",
    "\n",
    "print(\"Data shape and label shape\")\n",
    "print(X_data_.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "def shuffle_in_unison_inplace(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "# init the global var\n",
    "model = 0\n",
    "m = 13\n",
    "conv3d = False\n",
    "conv1d = False\n",
    "dimOrdering = 'tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3540, 10, 10, 20)\n",
      "Epoch 1/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.4788 - acc: 0.8198     \n",
      "Epoch 2/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.4622 - acc: 0.8333     \n",
      "Epoch 3/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.4118 - acc: 0.8333     \n",
      "Epoch 4/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.3822 - acc: 0.8333     \n",
      "Epoch 5/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.3743 - acc: 0.8333     \n",
      "Epoch 6/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.3182 - acc: 0.8333     \n",
      "Epoch 7/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.3288 - acc: 0.8333     \n",
      "Epoch 8/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2902 - acc: 0.8333     \n",
      "Epoch 9/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2591 - acc: 0.8333     \n",
      "Epoch 10/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2468 - acc: 0.8373     \n",
      "Epoch 11/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2543 - acc: 0.8977     \n",
      "Epoch 12/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2403 - acc: 0.8989     \n",
      "Epoch 13/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2175 - acc: 0.9333     \n",
      "Epoch 14/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2180 - acc: 0.9266     \n",
      "Epoch 15/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2153 - acc: 0.9339     \n",
      "Epoch 16/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1998 - acc: 0.9367     \n",
      "Epoch 17/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1883 - acc: 0.9373     \n",
      "Epoch 18/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1878 - acc: 0.9311     \n",
      "Epoch 19/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2002 - acc: 0.9333     \n",
      "Epoch 20/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1663 - acc: 0.9452     \n",
      "Epoch 21/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1675 - acc: 0.9497     \n",
      "Epoch 22/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1696 - acc: 0.9503     \n",
      "Epoch 23/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2029 - acc: 0.9384     \n",
      "Epoch 24/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1732 - acc: 0.9508     \n",
      "Epoch 25/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1708 - acc: 0.9514     \n",
      "Epoch 26/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1841 - acc: 0.9395     \n",
      "Epoch 27/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1598 - acc: 0.9503     \n",
      "Epoch 28/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1662 - acc: 0.9514     \n",
      "Epoch 29/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1722 - acc: 0.9514     \n",
      "Epoch 30/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1575 - acc: 0.9559     \n",
      "Epoch 31/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1391 - acc: 0.9638     \n",
      "Epoch 32/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1478 - acc: 0.9548     \n",
      "Epoch 33/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1417 - acc: 0.9605     \n",
      "Epoch 34/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1291 - acc: 0.9644     \n",
      "Epoch 35/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1402 - acc: 0.9621     \n",
      "Epoch 36/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1269 - acc: 0.9678     \n",
      "Epoch 37/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1114 - acc: 0.9757     \n",
      "Epoch 38/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1400 - acc: 0.9655     \n",
      "Epoch 39/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1284 - acc: 0.9689     \n",
      "Epoch 40/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1183 - acc: 0.9701     \n",
      "Epoch 41/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1429 - acc: 0.9616     \n",
      "Epoch 42/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1356 - acc: 0.9633     \n",
      "Epoch 43/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1264 - acc: 0.9610     \n",
      "Epoch 44/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1382 - acc: 0.9548     \n",
      "Epoch 45/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1806 - acc: 0.9333     \n",
      "Epoch 46/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1620 - acc: 0.9492     \n",
      "Epoch 47/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1262 - acc: 0.9605     \n",
      "Epoch 48/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1073 - acc: 0.9740     \n",
      "Epoch 49/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1029 - acc: 0.9723     \n",
      "Epoch 50/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1075 - acc: 0.9718     \n",
      "Epoch 51/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1212 - acc: 0.9695     \n",
      "Epoch 52/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1061 - acc: 0.9701     \n",
      "Epoch 53/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0830 - acc: 0.9831     \n",
      "Epoch 54/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0950 - acc: 0.9819     \n",
      "Epoch 55/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1062 - acc: 0.9729     \n",
      "Epoch 56/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1008 - acc: 0.9780     \n",
      "Epoch 57/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0864 - acc: 0.9808     \n",
      "Epoch 58/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0829 - acc: 0.9853     \n",
      "Epoch 59/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0801 - acc: 0.9808     \n",
      "Epoch 60/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0706 - acc: 0.9887     \n",
      "Epoch 61/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0779 - acc: 0.9876     \n",
      "Epoch 62/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0864 - acc: 0.9847     \n",
      "Epoch 63/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0997 - acc: 0.9757     \n",
      "Epoch 64/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0760 - acc: 0.9836     \n",
      "Epoch 65/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0955 - acc: 0.9768     \n",
      "Epoch 66/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0915 - acc: 0.9768     \n",
      "Epoch 67/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0822 - acc: 0.9797     \n",
      "Epoch 68/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0739 - acc: 0.9825     \n",
      "Epoch 69/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1094 - acc: 0.9644     \n",
      "Epoch 70/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2068 - acc: 0.9429     \n",
      "Epoch 71/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1460 - acc: 0.9458     \n",
      "Epoch 72/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0922 - acc: 0.9734     \n",
      "Epoch 73/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0870 - acc: 0.9768     \n",
      "Epoch 74/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0897 - acc: 0.9729     \n",
      "Epoch 75/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0592 - acc: 0.9853     \n",
      "Epoch 76/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0565 - acc: 0.9847     \n",
      "Epoch 77/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0460 - acc: 0.9887     \n",
      "Epoch 78/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0906 - acc: 0.9712     \n",
      "Epoch 79/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0805 - acc: 0.9678     \n",
      "Epoch 80/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0465 - acc: 0.9859     \n",
      "Epoch 81/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0558 - acc: 0.9831     \n",
      "Epoch 82/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0744 - acc: 0.9734     \n",
      "Epoch 83/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0711 - acc: 0.9785     \n",
      "Epoch 84/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0616 - acc: 0.9791     \n",
      "Epoch 85/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0404 - acc: 0.9887     \n",
      "Epoch 86/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0388 - acc: 0.9876     \n",
      "Epoch 87/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0325 - acc: 0.9927     \n",
      "Epoch 88/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1673 - acc: 0.9508     \n",
      "Epoch 89/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0887 - acc: 0.9751     \n",
      "Epoch 90/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0640 - acc: 0.9780     \n",
      "Epoch 91/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0733 - acc: 0.9734     \n",
      "Epoch 92/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0934 - acc: 0.9672     \n",
      "Epoch 93/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0673 - acc: 0.9797     \n",
      "Epoch 94/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0450 - acc: 0.9847     \n",
      "Epoch 95/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0498 - acc: 0.9881     \n",
      "Epoch 96/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0437 - acc: 0.9831     \n",
      "Epoch 97/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0679 - acc: 0.9763     \n",
      "Epoch 98/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0474 - acc: 0.9870     \n",
      "Epoch 99/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0419 - acc: 0.9910     \n",
      "Epoch 100/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0278 - acc: 0.9921     \n",
      "1728/1770 [============================>.] - ETA: 0sEpoch 1/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.4939 - acc: 0.8136     \n",
      "Epoch 2/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.4301 - acc: 0.8333     \n",
      "Epoch 3/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.4132 - acc: 0.8333     \n",
      "Epoch 4/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.4073 - acc: 0.8333     \n",
      "Epoch 5/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.3954 - acc: 0.8333     \n",
      "Epoch 6/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.3588 - acc: 0.8333     \n",
      "Epoch 7/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.3294 - acc: 0.8333     \n",
      "Epoch 8/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.3091 - acc: 0.8333     \n",
      "Epoch 9/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2859 - acc: 0.8333     \n",
      "Epoch 10/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2772 - acc: 0.8418     \n",
      "Epoch 11/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2562 - acc: 0.8938     \n",
      "Epoch 12/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2342 - acc: 0.9226     \n",
      "Epoch 13/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2320 - acc: 0.9266     \n",
      "Epoch 14/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.2259 - acc: 0.9243     \n",
      "Epoch 15/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1839 - acc: 0.9350     \n",
      "Epoch 16/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1804 - acc: 0.9412     \n",
      "Epoch 17/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1905 - acc: 0.9362     \n",
      "Epoch 18/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1571 - acc: 0.9480     \n",
      "Epoch 19/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1783 - acc: 0.9424     \n",
      "Epoch 20/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1676 - acc: 0.9441     \n",
      "Epoch 21/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1492 - acc: 0.9576     \n",
      "Epoch 22/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1243 - acc: 0.9616     \n",
      "Epoch 23/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1189 - acc: 0.9650     \n",
      "Epoch 24/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1209 - acc: 0.9616     \n",
      "Epoch 25/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1086 - acc: 0.9684     \n",
      "Epoch 26/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1041 - acc: 0.9684     \n",
      "Epoch 27/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1037 - acc: 0.9638     \n",
      "Epoch 28/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1052 - acc: 0.9650     \n",
      "Epoch 29/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0954 - acc: 0.9661     \n",
      "Epoch 30/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1168 - acc: 0.9599     \n",
      "Epoch 31/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1286 - acc: 0.9576     \n",
      "Epoch 32/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1122 - acc: 0.9667     \n",
      "Epoch 33/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1156 - acc: 0.9667     \n",
      "Epoch 34/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0825 - acc: 0.9768     \n",
      "Epoch 35/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0866 - acc: 0.9763     \n",
      "Epoch 36/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0728 - acc: 0.9808     \n",
      "Epoch 37/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0583 - acc: 0.9814     \n",
      "Epoch 38/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0867 - acc: 0.9774     \n",
      "Epoch 39/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0734 - acc: 0.9808     \n",
      "Epoch 40/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0654 - acc: 0.9814     \n",
      "Epoch 41/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0623 - acc: 0.9814     \n",
      "Epoch 42/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0730 - acc: 0.9814     \n",
      "Epoch 43/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0571 - acc: 0.9814     \n",
      "Epoch 44/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0808 - acc: 0.9780     \n",
      "Epoch 45/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0844 - acc: 0.9701     \n",
      "Epoch 46/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0632 - acc: 0.9842     \n",
      "Epoch 47/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0481 - acc: 0.9847     \n",
      "Epoch 48/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0664 - acc: 0.9785     \n",
      "Epoch 49/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0478 - acc: 0.9842     \n",
      "Epoch 50/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0478 - acc: 0.9887     \n",
      "Epoch 51/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0548 - acc: 0.9881     \n",
      "Epoch 52/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0668 - acc: 0.9814     \n",
      "Epoch 53/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0613 - acc: 0.9808     \n",
      "Epoch 54/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0640 - acc: 0.9825     \n",
      "Epoch 55/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0383 - acc: 0.9910     \n",
      "Epoch 56/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1035 - acc: 0.9763     \n",
      "Epoch 57/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0631 - acc: 0.9831     \n",
      "Epoch 58/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0735 - acc: 0.9768     \n",
      "Epoch 59/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0485 - acc: 0.9881     \n",
      "Epoch 60/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0348 - acc: 0.9859     \n",
      "Epoch 61/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0647 - acc: 0.9797     \n",
      "Epoch 62/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0439 - acc: 0.9842     \n",
      "Epoch 63/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0357 - acc: 0.9887     \n",
      "Epoch 64/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0275 - acc: 0.9915     \n",
      "Epoch 65/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0351 - acc: 0.9898     \n",
      "Epoch 66/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0343 - acc: 0.9915     \n",
      "Epoch 67/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0349 - acc: 0.9910     \n",
      "Epoch 68/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0506 - acc: 0.9864     \n",
      "Epoch 69/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0260 - acc: 0.9944     \n",
      "Epoch 70/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0207 - acc: 0.9955     \n",
      "Epoch 71/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0197 - acc: 0.9949     \n",
      "Epoch 72/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0159 - acc: 0.9966     \n",
      "Epoch 73/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0180 - acc: 0.9944     \n",
      "Epoch 74/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0372 - acc: 0.9881     \n",
      "Epoch 75/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0667 - acc: 0.9853     \n",
      "Epoch 76/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0811 - acc: 0.9825     \n",
      "Epoch 77/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0286 - acc: 0.9915     \n",
      "Epoch 78/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0193 - acc: 0.9955     \n",
      "Epoch 79/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0350 - acc: 0.9904     \n",
      "Epoch 80/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0112 - acc: 0.9966     \n",
      "Epoch 81/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0130 - acc: 0.9966     \n",
      "Epoch 82/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0242 - acc: 0.9932     \n",
      "Epoch 83/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0171 - acc: 0.9966     \n",
      "Epoch 84/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0114 - acc: 0.9966     \n",
      "Epoch 85/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0072 - acc: 0.9977     \n",
      "Epoch 86/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1044 - acc: 0.9763     \n",
      "Epoch 87/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0661 - acc: 0.9785     \n",
      "Epoch 88/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0408 - acc: 0.9842     \n",
      "Epoch 89/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0852 - acc: 0.9808     \n",
      "Epoch 90/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0399 - acc: 0.9904     \n",
      "Epoch 91/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.1640 - acc: 0.9616     \n",
      "Epoch 92/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0929 - acc: 0.9706     \n",
      "Epoch 93/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0542 - acc: 0.9825     \n",
      "Epoch 94/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0385 - acc: 0.9870     \n",
      "Epoch 95/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0171 - acc: 0.9944     \n",
      "Epoch 96/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0151 - acc: 0.9938     \n",
      "Epoch 97/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0158 - acc: 0.9949     \n",
      "Epoch 98/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0240 - acc: 0.9898     \n",
      "Epoch 99/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0205 - acc: 0.9932     \n",
      "Epoch 100/100\n",
      "1770/1770 [==============================] - 0s - loss: 0.0100 - acc: 0.9960     \n",
      "1728/1770 [============================>.] - ETA: 0sStandardized: 93.53% (0.65%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4330"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline():\n",
    "\n",
    "    nb_classes = 1\n",
    "\n",
    "    # create model\n",
    "    global model\n",
    "    if m ==7:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Convolution2D(10, 10, 2, border_mode='same',\n",
    "                                input_shape=(10,10,10)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(10, 3, 3))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Convolution2D(40, 5, 3, border_mode='same' ))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(40, 5, 3, border_mode='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(40, 5, 3))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "    if m == 11:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same',\n",
    "                                batch_input_shape=(10, 10, 10)))\n",
    "        # model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, 10, 10)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(Flatten(input_shape=(512,3,3)))\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "    if m ==13:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(20, 10, 10, border_mode='same', input_shape=(10,10,20), activation='relu', name='conv1_0'))\n",
    "#         model.add(ZeroPadding2D((2, 2)))\n",
    "        model.add(Convolution2D(20, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "        model.add(Convolution2D(20, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "    if m ==14:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(20, 10, 10, border_mode='same', input_shape=(10,10,20), activation='relu', name='conv1_0'))\n",
    "        model.add(Convolution2D(20, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "        model.add(Convolution2D(20, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "        model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Convolution2D(20, 10, 10, border_mode='same', input_shape=(10,10,20), activation='relu', name='conv2_0'))\n",
    "        model.add(Convolution2D(20, 5, 5, border_mode='same', activation='relu', name='conv2_1'))\n",
    "        model.add(Convolution2D(20, 10, 10, border_mode='same', activation='relu', name='conv2_2'))\n",
    "        model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "        \n",
    "    if m ==15:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Convolution2D(100,2,2, border_mode='same', \n",
    "                                input_shape=(20,10,10)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(50,2,2))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(60,4,4))\n",
    "#         model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "    \n",
    "    if m == 16:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Convolution3D(20,9,9,18, border_mode='same',\n",
    "                                input_shape=(1,10,10,20)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution3D(20,9,9,19))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#         model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        \n",
    "    if m ==18:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(ZeroPadding2D((1,1),input_shape=(20,10,10)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        \n",
    "    if m ==20:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution1D(100,10, activation='relu', input_shape=(100,10)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Convolution1D(100,10, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Convolution1D(100,10, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Convolution1D(100,10, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(MaxPooling1D((5)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4000, activation='relu'))\n",
    "        \n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# np.random.seed(seed)\n",
    "estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, nb_epoch=100,\n",
    "                                          batch_size=64, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(y=y_data, n_folds=2, shuffle=True)#, random_state=seed)\n",
    "if not conv1d and dimOrdering == 'th':\n",
    "    X_data = np.swapaxes(X_data_,1,3)\n",
    "    X_data = np.swapaxes(X_data,2,3)\n",
    "    print(X_data.shape)\n",
    "elif conv1d:\n",
    "    print(X_data_.shape)\n",
    "    X_data = X_data_.reshape((X_data_.shape[0], X_data_.shape[1]* X_data_.shape[2], X_data_.shape[3]))\n",
    "    print(X_data.shape)\n",
    "else:\n",
    "    X_data = X_data_\n",
    "\n",
    "if conv3d:\n",
    "    X_data =  np.expand_dims(X_data, 1)\n",
    "    \n",
    "print(X_data.shape)\n",
    "results = cross_val_score(pipeline,X_data, y_data, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "json_string = model.to_json()\n",
    "model.save_weights('my_model_weights_2d_%d.h5'%m, overwrite=True)\n",
    "open('my_model_architecture%d.json'%m, 'w').write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "(60, 50, 90)\n",
      "[10, 10, 20]\n"
     ]
    }
   ],
   "source": [
    "# we load a test case and the model\n",
    "\n",
    "# model = model_from_json(open('my_model_architecture%d.json'%m).read())\n",
    "# model.load_weights('my_model_weights_2d_%d.h5'%m)\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "print(data_spacing)\n",
    "nrrdData = nrrd.read(USERPATH + '/preprocessed_data/LabelMaps_%.2f-%.2f-%.2f/064/case.nrrd'%(tuple(data_spacing)))\n",
    "im = nrrdData[0]\n",
    "im = im[100:160,80:130,70:160]\n",
    "s = im.shape\n",
    "print(s)\n",
    "p=10\n",
    "print(patchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pyprind\n",
    "# import sys\n",
    "# def findtips(N):\n",
    "#     '''\n",
    "#     Find the tip in the image by computing testing patches at every voxel position\n",
    "#     TODO: make this method more efficient\n",
    "#     '''\n",
    "#     p0, p1, p2 = patchsize\n",
    "#     xmiddle = s[0]//2\n",
    "#     ymiddle = s[1]//2\n",
    "#     zmiddle = s[2]//2\n",
    "    \n",
    "#     x0= xmiddle - xmiddle//N\n",
    "#     y0= ymiddle - ymiddle//N\n",
    "#     z0= zmiddle - zmiddle//N\n",
    "    \n",
    "#     xe= xmiddle + xmiddle//N\n",
    "#     ye= ymiddle + ymiddle//N\n",
    "#     ze= zmiddle + zmiddle//N\n",
    "    \n",
    "#     tips = []\n",
    "#     bar = pyprind.ProgBar(xmiddle//N*2, title='Find_tip', stream=sys.stdout)\n",
    "#     for xi in range(x0, xe-p0):\n",
    "#         for yi in range(y0, ye-p1):\n",
    "#             vols = [im[xi:xi+p0,yi:yi+p1,zi:zi+p2] for zi in range(z0,ze-p2)]\n",
    "#             # we normalize the data (centered on mean 0 and rescaled in function of the STD)\n",
    "#             volnorm = [ x-np.mean(x) for x in vols]\n",
    "#             volnorm2 = [x/np.std(x) for x in volnorm]\n",
    "#             cube = np.array(volnorm2)\n",
    "#             cube = np.swapaxes(cube, 1,3)\n",
    "# #             cube = np.swapaxes(cube, 2,3)\n",
    "#             if conv3d:\n",
    "#                 cube = np.expand_dims(cube,1)\n",
    "#             res = model.predict_proba(cube, batch_size=ze-p2-z0, verbose=False)\n",
    "#             indices = np.where(res[:,0]==1)\n",
    "#             # we add the coordinates of the center voxel of the patches that tested positive\n",
    "#             for z in indices[0]:\n",
    "#                 tips.append([xi+p0/2,yi+p1/2,z0+p2/2+z])\n",
    "#         bar.update()\n",
    "#     return tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import sys\n",
    "def gettips(N):\n",
    "    '''\n",
    "    Find the tip in the image by computing testing patches at every voxel position\n",
    "    TODO: make this method more efficient\n",
    "    '''\n",
    "    p0, p1, p2 = patchsize\n",
    "    xmiddle = s[0]//2\n",
    "    ymiddle = s[1]//2\n",
    "    zmiddle = s[2]//2\n",
    "    \n",
    "    x0= xmiddle - xmiddle//N\n",
    "    y0= ymiddle - ymiddle//N\n",
    "    z0= zmiddle - zmiddle//N\n",
    "    \n",
    "    xe= xmiddle + xmiddle//N\n",
    "    ye= ymiddle + ymiddle//N\n",
    "    ze= zmiddle + zmiddle//N\n",
    "    \n",
    "    tips = []\n",
    "    bar = pyprind.ProgBar(xmiddle//N*2, title='Find_tip', stream=sys.stdout)\n",
    "    res = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            vols = [im[xi:xi+p0,yi:yi+p1,zi:zi+p2] for zi in range(z0,ze-p2)]\n",
    "            # we normalize the data (centered on mean 0 and rescaled in function of the STD)\n",
    "            volnorm = vols - np.mean(vols)\n",
    "            volnorm2 = volnorm/np.std(volnorm)\n",
    "#             volnorm = [ x-np.mean(x) for x in vols]\n",
    "#             volnorm2 = [x/np.std(x) for x in volnorm]\n",
    "            cube = np.array(volnorm2)\n",
    "            if not conv1d and dimOrdering == 'th':\n",
    "                cube = np.swapaxes(cube, 1,3)\n",
    "            if conv3d:\n",
    "                cube = np.expand_dims(cube,1)\n",
    "            if conv1d:\n",
    "                cube = cube.reshape(cube.shape[0], cube.shape[1]*cube.shape[2],cube.shape[3])\n",
    "            res.append(model.predict_proba(cube, batch_size=ze-p2-z0, verbose=False))\n",
    "        bar.update()\n",
    "    return res\n",
    "\n",
    "def findtips(res, prob):\n",
    "    N=1\n",
    "    p0, p1, p2 = patchsize\n",
    "    xmiddle = s[0]//2\n",
    "    ymiddle = s[1]//2\n",
    "    zmiddle = s[2]//2\n",
    "    \n",
    "    x0= xmiddle - xmiddle//N\n",
    "    y0= ymiddle - ymiddle//N\n",
    "    z0= zmiddle - zmiddle//N\n",
    "    \n",
    "    xe= xmiddle + xmiddle//N\n",
    "    ye= ymiddle + ymiddle//N\n",
    "    ze= zmiddle + zmiddle//N\n",
    "    \n",
    "    i = -1\n",
    "    tips = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            i+=1\n",
    "            indices = np.where(res[i][:,0]>=prob)\n",
    "            # we add the coordinates of the center voxel of the patches that tested positive\n",
    "            for z in indices[0]:\n",
    "                tips.append([xi+p0/2,yi+p1/2,z0+p2/2+z])\n",
    "    return tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find_tip\n",
      "0%                          100%\n",
      "[########################      ] | ETA: 00:00:05"
     ]
    }
   ],
   "source": [
    "# find the tips for patches with size p\n",
    "pred=gettips(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7620"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pred))\n",
    "res = findtips(pred, 1)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of a labelmap from the voxel that tested positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(im.shape)\n",
    "for coord in res:\n",
    "    mask[int(coord[0]),int(coord[1]),int(coord[2])]=1.0\n",
    "nrrd.write('mask%d.nrrd'%m, mask)\n",
    "nrrd.write('im%d.nrrd'%m, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd816c81ac8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAADyCAYAAABQ+fHRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd816d67dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "# We display one axial slice\n",
    "Z = 17\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow((np.clip(mask[:,:,Z]*255+im[:,:,Z]/2,a_min=0,a_max=200)).transpose(),  cmap='gray', interpolation='nearest')\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.imshow(im[:,:,Z].transpose(), cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
