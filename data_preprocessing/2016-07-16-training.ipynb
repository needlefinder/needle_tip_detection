{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n",
      "/home/ubuntu/preprocessed_data/tips_10-10-20_1.00-1.00-1.00/\n",
      "number of sample 590\n",
      "number of sample 9400\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from __future__ import division\n",
    "import joblib\n",
    "import glob\n",
    "import os, re\n",
    "import numpy as np\n",
    "import nrrd\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics, decomposition\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "from joblib import Parallel, delayed  \n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "USERPATH = os.path.expanduser(\"~\")\n",
    "print(USERPATH)\n",
    "import six.moves.cPickle as pickle\n",
    "# import tensorflow as tf\n",
    "\n",
    "# import theano\n",
    "# theano.config.device = 'gpu'\n",
    "# theano.config.floatX = 'float32'\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# server = tf.train.Server.create_local_server()\n",
    "# sess = tf.Session(server.target)\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(sess)\n",
    "\n",
    "# tb = TensorBoard(log_dir='/tmp/tensorboard', histogram_freq=1, write_graph=True)\n",
    "\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# checkpointer = ModelCheckpoint(filepath=\"weights2d.hdf5\", verbose=1, save_best_only=True)\n",
    "patchsize = [10,10,20]\n",
    "data_spacing = [1,1,1]\n",
    "notipsPath = USERPATH + \"/preprocessed_data/notips_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "tipsPath = USERPATH + \"/preprocessed_data/tips_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "\n",
    "casesToExclude = [64,77]\n",
    "\n",
    "\n",
    "def getTrainingPaths(tipsPath, cases=[64,77]):\n",
    "    strL = \"\"\n",
    "    for c in cases:\n",
    "        strL+=\"%03d|\"%c\n",
    "    fnames=glob.glob(tipsPath + \"/*/*.nrrd\")\n",
    "    regex=re.compile(\"^((?!%s).)*$\"%strL[:-1])\n",
    "    paths = [m.group(0) for l in fnames for m in [regex.search(l)] if m]\n",
    "    return paths\n",
    "\n",
    "def loadAllDataFromPath(path, casesToExclude):\n",
    "    # path in directorty\n",
    "    \n",
    "#     cubeTipsPath = glob.glob(path + \"/*/*.nrrd\")\n",
    "    cubeTipsPath = getTrainingPaths(path, casesToExclude)\n",
    "    # number of samples\n",
    "    N = len(cubeTipsPath)\n",
    "    \n",
    "    cubeTips = []\n",
    "    data = []\n",
    "    for path_i in cubeTipsPath:\n",
    "        cubeTips.append(nrrd.read(path_i))\n",
    "    for i in range(N):\n",
    "        # c = np.array(cubeTips[i][0])  # for patches of size 20,20,20\n",
    "        c = np.array(cubeTips[i][0][:,:,:]) # for patches of size 10,10,10\n",
    "        if c.shape==tuple(patchsize):\n",
    "            data.append(np.array(c))\n",
    "    output = np.array(data, dtype='float32')\n",
    "    print('number of sample %d' %len(output))\n",
    "    return output\n",
    "\n",
    "\n",
    "print(tipsPath)\n",
    "tips = loadAllDataFromPath(tipsPath, casesToExclude)\n",
    "notips = loadAllDataFromPath(notipsPath, casesToExclude)[:10*len(tips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590 5900\n",
      "target shape: (6490,)\n",
      "data shape: (6490, 10, 10, 20)\n"
     ]
    }
   ],
   "source": [
    "print(len(tips), len(notips))\n",
    "\n",
    "target_0 = [0 for i in range(len(notips))]\n",
    "target_1 = [1 for i in range(len(tips))]\n",
    "y_train = np.array(target_0 + target_1)\n",
    "print('target shape:', y_train.shape)\n",
    "X_train = np.array(list(notips)+list(tips))\n",
    "\n",
    "print('data shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape and label shape\n",
      "(6490, 10, 10, 20) (6490,)\n"
     ]
    }
   ],
   "source": [
    "o = 7\n",
    "f_Xtrain = open('X_data_n%d.save'%o, 'wb')\n",
    "f_ytrain = open('y_data_n%d.save'%o, 'wb')\n",
    "\n",
    "pickle.dump(X_train, f_Xtrain, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(y_train, f_ytrain, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "f_Xtrain.close()\n",
    "f_ytrain.close()\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "# Load the dataset\n",
    "f_Xdata = open('X_data_n%d.save'%o, 'rb')\n",
    "f_ydata = open('y_data_n%d.save'%o, 'rb')\n",
    "\n",
    "X_data_ = pickle.load(f_Xdata)\n",
    "X_data_ = X_data_.astype('float32')\n",
    "\n",
    "# normalize the raw data\n",
    "X_data_ -= np.mean(X_data_)\n",
    "X_data_ /= np.std(X_data_)\n",
    "\n",
    "## second method for normalization\n",
    "# X_data /= 255\n",
    "\n",
    "y_data= pickle.load(f_ydata)\n",
    "y_data_binary = to_categorical(y_data)\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_data)\n",
    "y_data = encoder.transform(y_data)\n",
    "\n",
    "print(\"Data shape and label shape\")\n",
    "print(X_data_.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "def shuffle_in_unison_inplace(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "# init the global var\n",
    "model = 0\n",
    "m = 17\n",
    "conv3d = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6490, 20, 10, 10)\n",
      "Epoch 1/100\n",
      "3245/3245 [==============================] - 8s - loss: 0.3173 - acc: 0.9014     \n",
      "Epoch 2/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.2116 - acc: 0.9180     \n",
      "Epoch 3/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.1302 - acc: 0.9602     \n",
      "Epoch 4/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0764 - acc: 0.9744     \n",
      "Epoch 5/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0647 - acc: 0.9778     \n",
      "Epoch 6/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0422 - acc: 0.9867     \n",
      "Epoch 7/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0317 - acc: 0.9877     \n",
      "Epoch 8/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0319 - acc: 0.9886     \n",
      "Epoch 9/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0377 - acc: 0.9901     \n",
      "Epoch 10/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0402 - acc: 0.9911     \n",
      "Epoch 11/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0219 - acc: 0.9904     \n",
      "Epoch 12/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0199 - acc: 0.9935     \n",
      "Epoch 13/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0193 - acc: 0.9945     \n",
      "Epoch 14/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0146 - acc: 0.9960     \n",
      "Epoch 15/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0113 - acc: 0.9960     \n",
      "Epoch 16/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0115 - acc: 0.9954     \n",
      "Epoch 17/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0285 - acc: 0.9917     \n",
      "Epoch 18/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0180 - acc: 0.9960     \n",
      "Epoch 19/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0256 - acc: 0.9929     \n",
      "Epoch 20/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0280 - acc: 0.9895     \n",
      "Epoch 21/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0290 - acc: 0.9889     \n",
      "Epoch 22/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0247 - acc: 0.9932     \n",
      "Epoch 23/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0187 - acc: 0.9945     \n",
      "Epoch 24/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0151 - acc: 0.9941     \n",
      "Epoch 25/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0086 - acc: 0.9969     \n",
      "Epoch 26/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0119 - acc: 0.9963     \n",
      "Epoch 27/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0325 - acc: 0.9908     \n",
      "Epoch 28/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0101 - acc: 0.9969     \n",
      "Epoch 29/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0145 - acc: 0.9966     \n",
      "Epoch 30/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0244 - acc: 0.9938     \n",
      "Epoch 31/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0126 - acc: 0.9951     \n",
      "Epoch 32/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0017 - acc: 0.9997     \n",
      "Epoch 33/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.1024 - acc: 0.9784     \n",
      "Epoch 34/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0513 - acc: 0.9837     \n",
      "Epoch 35/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0235 - acc: 0.9904     \n",
      "Epoch 36/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0205 - acc: 0.9935     \n",
      "Epoch 37/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0201 - acc: 0.9926     \n",
      "Epoch 38/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0194 - acc: 0.9932     \n",
      "Epoch 39/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0094 - acc: 0.9969     \n",
      "Epoch 40/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0058 - acc: 0.9985     \n",
      "Epoch 41/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0025 - acc: 0.9991     \n",
      "Epoch 42/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0153 - acc: 0.9982     \n",
      "Epoch 43/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0259 - acc: 0.9917     \n",
      "Epoch 44/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0204 - acc: 0.9938     \n",
      "Epoch 45/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0187 - acc: 0.9975     \n",
      "Epoch 46/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0229 - acc: 0.9945     \n",
      "Epoch 47/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0218 - acc: 0.9957     \n",
      "Epoch 48/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0170 - acc: 0.9969     \n",
      "Epoch 49/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0220 - acc: 0.9932     \n",
      "Epoch 50/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0076 - acc: 0.9969     \n",
      "Epoch 51/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0211 - acc: 0.9938     \n",
      "Epoch 52/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0180 - acc: 0.9945     \n",
      "Epoch 53/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0057 - acc: 0.9975     \n",
      "Epoch 54/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0028 - acc: 0.9991     \n",
      "Epoch 55/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0015 - acc: 0.9994     \n",
      "Epoch 56/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0011 - acc: 0.9994     \n",
      "Epoch 57/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0034 - acc: 0.9991     \n",
      "Epoch 58/100\n",
      "3245/3245 [==============================] - 5s - loss: 6.9852e-04 - acc: 0.9997     \n",
      "Epoch 59/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.1731e-04 - acc: 1.0000     \n",
      "Epoch 60/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.7247e-05 - acc: 1.0000     \n",
      "Epoch 61/100\n",
      "3245/3245 [==============================] - 5s - loss: 5.1101e-06 - acc: 1.0000     \n",
      "Epoch 62/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.9199e-06 - acc: 1.0000     \n",
      "Epoch 63/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.2152e-06 - acc: 1.0000     \n",
      "Epoch 64/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.3554e-06 - acc: 1.0000     \n",
      "Epoch 65/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.3383e-06 - acc: 1.0000     \n",
      "Epoch 66/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.6354e-06 - acc: 1.0000     \n",
      "Epoch 67/100\n",
      "3245/3245 [==============================] - 5s - loss: 6.2030e-07 - acc: 1.0000     \n",
      "Epoch 68/100\n",
      "3245/3245 [==============================] - 5s - loss: 7.6824e-07 - acc: 1.0000     \n",
      "Epoch 69/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.0073e-06 - acc: 1.0000     \n",
      "Epoch 70/100\n",
      "3245/3245 [==============================] - 5s - loss: 9.6618e-07 - acc: 1.0000     \n",
      "Epoch 71/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.1295e-07 - acc: 1.0000     \n",
      "Epoch 72/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.0248e-07 - acc: 1.0000     \n",
      "Epoch 73/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.0461e-07 - acc: 1.0000     \n",
      "Epoch 74/100\n",
      "3245/3245 [==============================] - 5s - loss: 5.2244e-07 - acc: 1.0000     \n",
      "Epoch 75/100\n",
      "3245/3245 [==============================] - 5s - loss: 5.2325e-07 - acc: 1.0000     \n",
      "Epoch 76/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.6723e-07 - acc: 1.0000     \n",
      "Epoch 77/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.2853e-07 - acc: 1.0000     \n",
      "Epoch 78/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.9337e-07 - acc: 1.0000     \n",
      "Epoch 79/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.4833e-07 - acc: 1.0000     \n",
      "Epoch 80/100\n",
      "3245/3245 [==============================] - 5s - loss: 7.4052e-07 - acc: 1.0000     \n",
      "Epoch 81/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.0164e-07 - acc: 1.0000     \n",
      "Epoch 82/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.6693e-07 - acc: 1.0000     \n",
      "Epoch 83/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.9507e-07 - acc: 1.0000     \n",
      "Epoch 84/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.2916e-07 - acc: 1.0000     \n",
      "Epoch 85/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.0142e-07 - acc: 1.0000     \n",
      "Epoch 86/100\n",
      "3245/3245 [==============================] - 5s - loss: 4.6709e-07 - acc: 1.0000     \n",
      "Epoch 87/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.1376e-07 - acc: 1.0000     \n",
      "Epoch 88/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.4882e-07 - acc: 1.0000     \n",
      "Epoch 89/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.7327e-07 - acc: 1.0000     \n",
      "Epoch 90/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.7380e-07 - acc: 1.0000     \n",
      "Epoch 91/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.4142e-07 - acc: 1.0000     \n",
      "Epoch 92/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.7953e-07 - acc: 1.0000     \n",
      "Epoch 93/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.6223e-07 - acc: 1.0000     \n",
      "Epoch 94/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.5113e-07 - acc: 1.0000     \n",
      "Epoch 95/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.7409e-07 - acc: 1.0000     \n",
      "Epoch 96/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.3530e-07 - acc: 1.0000     \n",
      "Epoch 97/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.3174e-07 - acc: 1.0000     \n",
      "Epoch 98/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.7281e-07 - acc: 1.0000     \n",
      "Epoch 99/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.8831e-07 - acc: 1.0000     \n",
      "Epoch 100/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.4118e-07 - acc: 1.0000     \n",
      "3245/3245 [==============================] - 1s     \n",
      "Epoch 1/100\n",
      "3245/3245 [==============================] - 8s - loss: 0.4056 - acc: 0.8937     \n",
      "Epoch 2/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.2819 - acc: 0.9091     \n",
      "Epoch 3/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.2078 - acc: 0.9091     \n",
      "Epoch 4/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.1498 - acc: 0.9451     \n",
      "Epoch 5/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0913 - acc: 0.9670     \n",
      "Epoch 6/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0646 - acc: 0.9800     \n",
      "Epoch 7/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0598 - acc: 0.9827     \n",
      "Epoch 8/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0548 - acc: 0.9815     \n",
      "Epoch 9/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0393 - acc: 0.9874     \n",
      "Epoch 10/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0496 - acc: 0.9864     \n",
      "Epoch 11/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0388 - acc: 0.9871     \n",
      "Epoch 12/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0539 - acc: 0.9831     \n",
      "Epoch 13/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0339 - acc: 0.9892     \n",
      "Epoch 14/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0318 - acc: 0.9908     \n",
      "Epoch 15/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0510 - acc: 0.9846     \n",
      "Epoch 16/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0325 - acc: 0.9883     \n",
      "Epoch 17/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0230 - acc: 0.9917     \n",
      "Epoch 18/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0173 - acc: 0.9938     \n",
      "Epoch 19/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0197 - acc: 0.9945     \n",
      "Epoch 20/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0159 - acc: 0.9954     \n",
      "Epoch 21/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0357 - acc: 0.9904     \n",
      "Epoch 22/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0431 - acc: 0.9874     \n",
      "Epoch 23/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0359 - acc: 0.9892     \n",
      "Epoch 24/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0075 - acc: 0.9978     \n",
      "Epoch 25/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0408 - acc: 0.9864     \n",
      "Epoch 26/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0291 - acc: 0.9911     \n",
      "Epoch 27/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0128 - acc: 0.9957     \n",
      "Epoch 28/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0154 - acc: 0.9960     \n",
      "Epoch 29/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0297 - acc: 0.9926     \n",
      "Epoch 30/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0274 - acc: 0.9895     \n",
      "Epoch 31/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0092 - acc: 0.9969     \n",
      "Epoch 32/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0151 - acc: 0.9966     \n",
      "Epoch 33/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0136 - acc: 0.9960     \n",
      "Epoch 34/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0221 - acc: 0.9945     \n",
      "Epoch 35/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0226 - acc: 0.9945     \n",
      "Epoch 36/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0094 - acc: 0.9982     \n",
      "Epoch 37/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0273 - acc: 0.9911     \n",
      "Epoch 38/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0294 - acc: 0.9914     \n",
      "Epoch 39/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0111 - acc: 0.9966     \n",
      "Epoch 40/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0067 - acc: 0.9975     \n",
      "Epoch 41/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0064 - acc: 0.9985     \n",
      "Epoch 42/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0088 - acc: 0.9975     \n",
      "Epoch 43/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0068 - acc: 0.9985     \n",
      "Epoch 44/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0111 - acc: 0.9945     \n",
      "Epoch 45/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0084 - acc: 0.9982     \n",
      "Epoch 46/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0097 - acc: 0.9972     \n",
      "Epoch 47/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0086 - acc: 0.9975     \n",
      "Epoch 48/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0149 - acc: 0.9966     \n",
      "Epoch 49/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0135 - acc: 0.9954     \n",
      "Epoch 50/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0223 - acc: 0.9951     \n",
      "Epoch 51/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0242 - acc: 0.9938     \n",
      "Epoch 52/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0350 - acc: 0.9917     \n",
      "Epoch 53/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0296 - acc: 0.9908     \n",
      "Epoch 54/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0237 - acc: 0.9932     \n",
      "Epoch 55/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0097 - acc: 0.9966     \n",
      "Epoch 56/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0080 - acc: 0.9969     \n",
      "Epoch 57/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0154 - acc: 0.9975     \n",
      "Epoch 58/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0168 - acc: 0.9957     \n",
      "Epoch 59/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0050 - acc: 0.9988     \n",
      "Epoch 60/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0042 - acc: 0.9991     \n",
      "Epoch 61/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0130 - acc: 0.9972     \n",
      "Epoch 62/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0102 - acc: 0.9957     \n",
      "Epoch 63/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0087 - acc: 0.9985     \n",
      "Epoch 64/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0052 - acc: 0.9997     \n",
      "Epoch 65/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0080 - acc: 0.9988     \n",
      "Epoch 66/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0161 - acc: 0.9957     \n",
      "Epoch 67/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0195 - acc: 0.9960     \n",
      "Epoch 68/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0136 - acc: 0.9978     \n",
      "Epoch 69/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0060 - acc: 0.9982     \n",
      "Epoch 70/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0020 - acc: 0.9991     \n",
      "Epoch 71/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0029 - acc: 0.9985     \n",
      "Epoch 72/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0133 - acc: 0.9969     \n",
      "Epoch 73/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0113 - acc: 0.9954     \n",
      "Epoch 74/100\n",
      "3245/3245 [==============================] - 5s - loss: 0.0017 - acc: 0.9994     \n",
      "Epoch 75/100\n",
      "3245/3245 [==============================] - 5s - loss: 4.7097e-04 - acc: 1.0000     \n",
      "Epoch 76/100\n",
      "3245/3245 [==============================] - 5s - loss: 4.6399e-04 - acc: 0.9997     \n",
      "Epoch 77/100\n",
      "3245/3245 [==============================] - 5s - loss: 6.1816e-05 - acc: 1.0000     \n",
      "Epoch 78/100\n",
      "3245/3245 [==============================] - 5s - loss: 7.0388e-06 - acc: 1.0000     \n",
      "Epoch 79/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.1539e-06 - acc: 1.0000     \n",
      "Epoch 80/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.6858e-06 - acc: 1.0000     \n",
      "Epoch 81/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.9201e-06 - acc: 1.0000     \n",
      "Epoch 82/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.5762e-06 - acc: 1.0000     \n",
      "Epoch 83/100\n",
      "3245/3245 [==============================] - 5s - loss: 4.0343e-07 - acc: 1.0000     \n",
      "Epoch 84/100\n",
      "3245/3245 [==============================] - 5s - loss: 9.2134e-07 - acc: 1.0000     \n",
      "Epoch 85/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.5638e-07 - acc: 1.0000     \n",
      "Epoch 86/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.7008e-07 - acc: 1.0000     \n",
      "Epoch 87/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.2741e-07 - acc: 1.0000     \n",
      "Epoch 88/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.1274e-07 - acc: 1.0000     \n",
      "Epoch 89/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.0173e-07 - acc: 1.0000     \n",
      "Epoch 90/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.1894e-07 - acc: 1.0000     \n",
      "Epoch 91/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.5282e-07 - acc: 1.0000     \n",
      "Epoch 92/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.9338e-07 - acc: 1.0000     \n",
      "Epoch 93/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.4775e-07 - acc: 1.0000     \n",
      "Epoch 94/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.0638e-07 - acc: 1.0000     \n",
      "Epoch 95/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.7001e-07 - acc: 1.0000     \n",
      "Epoch 96/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.4477e-07 - acc: 1.0000     \n",
      "Epoch 97/100\n",
      "3245/3245 [==============================] - 5s - loss: 2.1336e-07 - acc: 1.0000     \n",
      "Epoch 98/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.6924e-07 - acc: 1.0000     \n",
      "Epoch 99/100\n",
      "3245/3245 [==============================] - 5s - loss: 1.7957e-07 - acc: 1.0000     \n",
      "Epoch 100/100\n",
      "3245/3245 [==============================] - 5s - loss: 3.2960e-07 - acc: 1.0000     \n",
      "3245/3245 [==============================] - 1s     \n",
      "Standardized: 97.24% (0.20%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5474"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline():\n",
    "\n",
    "    nb_classes = 1\n",
    "\n",
    "    # create model\n",
    "    global model\n",
    "    if m ==7:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Convolution2D(10, 10, 2, border_mode='same',\n",
    "                                input_shape=(10,10,10)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(10, 3, 3))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Convolution2D(40, 5, 3, border_mode='same' ))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(40, 5, 3, border_mode='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(40, 5, 3))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "    if m == 11:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same',\n",
    "                                batch_input_shape=(10, 10, 10)))\n",
    "        # model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, 10, 10)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(Flatten(input_shape=(512,3,3)))\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "    if m ==13:\n",
    "        model = Sequential()\n",
    "        model.add(ZeroPadding2D((1, 1), input_shape=(10,10,10)))\n",
    "        model.add(Convolution2D(10, 10, 2, border_mode='same',\n",
    "                                ))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        #\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        #\n",
    "        # model.add(ZeroPadding2D((1, 1)))\n",
    "        # model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "        # model.add(ZeroPadding2D((1, 1)))\n",
    "        # model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "        # model.add(ZeroPadding2D((1, 1)))\n",
    "        # model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "        # model.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "\n",
    "        # model.add(Convolution2D(40, 3, 3, border_mode='same' ))\n",
    "        # model.add(Activation('relu'))\n",
    "        # model.add(Convolution2D(40, 3, 3, border_mode='same'))\n",
    "        # model.add(Activation('relu'))\n",
    "        # model.add(Convolution2D(40, 3, 3))\n",
    "        # model.add(Activation('relu'))\n",
    "        # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        # model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512*3*3))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        \n",
    "    if m ==14:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Convolution2D(20,9,9, border_mode='same',\n",
    "                                input_shape=(10,10,10)))\n",
    "#         model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(20,9,9))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "#         model.add(Convolution2D(40, 5, 3, border_mode='same' ))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(40, 5, 3, border_mode='same'))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(40, 5, 3))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#         model.add(Dropout(0.1))\n",
    "\n",
    "        model.add(Flatten())\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        \n",
    "        \n",
    "    if m ==15:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Convolution2D(100,2,2, border_mode='same', \n",
    "                                input_shape=(20,10,10)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution2D(50,2,2))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(60,4,4))\n",
    "#         model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "    \n",
    "    if m == 16:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Convolution3D(20,9,9,18, border_mode='same',\n",
    "                                input_shape=(1,10,10,20)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Convolution3D(20,9,9,19))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#         model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(480))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        \n",
    "    if m ==17:\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(ZeroPadding2D((1,1),input_shape=(20,10,10)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "        model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# np.random.seed(seed)\n",
    "estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, nb_epoch=100,\n",
    "                                          batch_size=128, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(y=y_data, n_folds=2, shuffle=True)#, random_state=seed)\n",
    "\n",
    "X_data = np.swapaxes(X_data_,1,3)\n",
    "X_data = np.swapaxes(X_data,2,3)\n",
    "print(X_data.shape)\n",
    "if conv3d:\n",
    "    X_data =  np.expand_dims(X_data, 1)\n",
    "\n",
    "results = cross_val_score(pipeline,X_data, y_data, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "json_string = model.to_json()\n",
    "model.save_weights('my_model_weights_2d_%d.h5'%m, overwrite=True)\n",
    "open('my_model_architecture%d.json'%m, 'w').write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "(60, 50, 90)\n",
      "[10, 10, 20]\n"
     ]
    }
   ],
   "source": [
    "# we load a test case and the model\n",
    "\n",
    "# model = model_from_json(open('my_model_architecture%d.json'%m).read())\n",
    "# model.load_weights('my_model_weights_2d_%d.h5'%m)\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "print(data_spacing)\n",
    "nrrdData = nrrd.read(USERPATH + '/preprocessed_data/LabelMaps_%.2f-%.2f-%.2f/064/case.nrrd'%(tuple(data_spacing)))\n",
    "im = nrrdData[0]\n",
    "im = im[100:160,80:130,70:160]\n",
    "s = im.shape\n",
    "print(s)\n",
    "p=10\n",
    "print(patchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pyprind\n",
    "# import sys\n",
    "# def findtips(N):\n",
    "#     '''\n",
    "#     Find the tip in the image by computing testing patches at every voxel position\n",
    "#     TODO: make this method more efficient\n",
    "#     '''\n",
    "#     p0, p1, p2 = patchsize\n",
    "#     xmiddle = s[0]//2\n",
    "#     ymiddle = s[1]//2\n",
    "#     zmiddle = s[2]//2\n",
    "    \n",
    "#     x0= xmiddle - xmiddle//N\n",
    "#     y0= ymiddle - ymiddle//N\n",
    "#     z0= zmiddle - zmiddle//N\n",
    "    \n",
    "#     xe= xmiddle + xmiddle//N\n",
    "#     ye= ymiddle + ymiddle//N\n",
    "#     ze= zmiddle + zmiddle//N\n",
    "    \n",
    "#     tips = []\n",
    "#     bar = pyprind.ProgBar(xmiddle//N*2, title='Find_tip', stream=sys.stdout)\n",
    "#     for xi in range(x0, xe-p0):\n",
    "#         for yi in range(y0, ye-p1):\n",
    "#             vols = [im[xi:xi+p0,yi:yi+p1,zi:zi+p2] for zi in range(z0,ze-p2)]\n",
    "#             # we normalize the data (centered on mean 0 and rescaled in function of the STD)\n",
    "#             volnorm = [ x-np.mean(x) for x in vols]\n",
    "#             volnorm2 = [x/np.std(x) for x in volnorm]\n",
    "#             cube = np.array(volnorm2)\n",
    "#             cube = np.swapaxes(cube, 1,3)\n",
    "# #             cube = np.swapaxes(cube, 2,3)\n",
    "#             if conv3d:\n",
    "#                 cube = np.expand_dims(cube,1)\n",
    "#             res = model.predict_proba(cube, batch_size=ze-p2-z0, verbose=False)\n",
    "#             indices = np.where(res[:,0]==1)\n",
    "#             # we add the coordinates of the center voxel of the patches that tested positive\n",
    "#             for z in indices[0]:\n",
    "#                 tips.append([xi+p0/2,yi+p1/2,z0+p2/2+z])\n",
    "#         bar.update()\n",
    "#     return tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import sys\n",
    "def gettips(N):\n",
    "    '''\n",
    "    Find the tip in the image by computing testing patches at every voxel position\n",
    "    TODO: make this method more efficient\n",
    "    '''\n",
    "    p0, p1, p2 = patchsize\n",
    "    xmiddle = s[0]//2\n",
    "    ymiddle = s[1]//2\n",
    "    zmiddle = s[2]//2\n",
    "    \n",
    "    x0= xmiddle - xmiddle//N\n",
    "    y0= ymiddle - ymiddle//N\n",
    "    z0= zmiddle - zmiddle//N\n",
    "    \n",
    "    xe= xmiddle + xmiddle//N\n",
    "    ye= ymiddle + ymiddle//N\n",
    "    ze= zmiddle + zmiddle//N\n",
    "    \n",
    "    tips = []\n",
    "    bar = pyprind.ProgBar(xmiddle//N*2, title='Find_tip', stream=sys.stdout)\n",
    "    res = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            vols = [im[xi:xi+p0,yi:yi+p1,zi:zi+p2] for zi in range(z0,ze-p2)]\n",
    "            # we normalize the data (centered on mean 0 and rescaled in function of the STD)\n",
    "            volnorm = [ x-np.mean(x) for x in vols]\n",
    "            volnorm2 = [x/np.std(x) for x in volnorm]\n",
    "            cube = np.array(volnorm2)\n",
    "            cube = np.swapaxes(cube, 1,3)\n",
    "#             cube = np.swapaxes(cube, 2,3)\n",
    "            if conv3d:\n",
    "                cube = np.expand_dims(cube,1)\n",
    "            res.append(model.predict_proba(cube, batch_size=ze-p2-z0, verbose=False))\n",
    "        bar.update()\n",
    "    return res\n",
    "\n",
    "def findtips(res, prob):\n",
    "    N=1\n",
    "    p0, p1, p2 = patchsize\n",
    "    xmiddle = s[0]//2\n",
    "    ymiddle = s[1]//2\n",
    "    zmiddle = s[2]//2\n",
    "    \n",
    "    x0= xmiddle - xmiddle//N\n",
    "    y0= ymiddle - ymiddle//N\n",
    "    z0= zmiddle - zmiddle//N\n",
    "    \n",
    "    xe= xmiddle + xmiddle//N\n",
    "    ye= ymiddle + ymiddle//N\n",
    "    ze= zmiddle + zmiddle//N\n",
    "    \n",
    "    i = -1\n",
    "    tips = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            i+=1\n",
    "            indices = np.where(res[i][:,0]>=prob)\n",
    "            # we add the coordinates of the center voxel of the patches that tested positive\n",
    "            for z in indices[0]:\n",
    "                tips.append([xi+p0/2,yi+p1/2,z0+p2/2+z])\n",
    "    return tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find_tip\n",
      "0%                          100%\n",
      "[########################      ] | ETA: 00:00:13"
     ]
    }
   ],
   "source": [
    "# find the tips for patches with size p\n",
    "pred=gettips(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9331"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pred))\n",
    "res = findtips(pred, 1)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of a labelmap from the voxel that tested positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(im.shape)\n",
    "for coord in res:\n",
    "    mask[int(coord[0]),int(coord[1]),int(coord[2])]=1.0\n",
    "nrrd.write('mask%d.nrrd'%m, mask)\n",
    "nrrd.write('im%d.nrrd'%m, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8cacdecc50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAADyCAYAAABQ+fHRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztvWusXld17v/MQAhQ4sR2Yju2E+PcnBu5QW5NIBAgXE6B\nth+qnh4dQav2S09F1ctRIecDX1rRQqUI9QgpEoVSqvz/KSgUTgVNgABNQ0jcXG3HieNr7Njeju0k\ndkJu4HU+eG+fNX9z+J1zb7/efvfm+UlRPNa71lxzzTnXeNde43nHSF3XyRhjjDHGDOa4Y90BY4wx\nxpiZgB+ajDHGGGMa8EOTMcYYY0wDfmgyxhhjjGnAD03GGGOMMQ34ockYY4wxpoEjemhKKX0wpfR4\nSmldSukvhtUpY4yZDuzDjDGTIU01T1NK6ThJ6yS9V9J2SSsl/XbXdY8Pr3vGGHN0sA8zxkyW1x/B\nsVdKerLrui2SlFL6/yV9TFLmcFJKzp5pzC8hXdelY92HClUfZv9lzC8nh/NfR/LQtETS1p69TQed\nULnjkiXat2+f5syZo5///OfZZyeccELZqdfn3XrjG9+Y2SeffHJmv+lNb6q2kVJ+/TzvihUrJEn/\n8R//oeuuu06StH///myff//3f8/sHTt2ZPYZZ5xR9OPUU08ttvV59dVXMzt687d9+/bMfstb3nLo\n/KeddpoWLFiQff6GN7yhaINj+OY3vzmzX3vttYH9kqRXXnll4DHHH398Zp944omSpFWrVultb3ub\nJGnevHnZPrt3787sn/3sZ5l93HFlBHnLli2ZvWbNmszmejj33HOLNib6NsFZZ52lBx54QG9/+9sl\nSVdemS/lPXv2FG3867/+a2Y/9NBDmc01x2uTyuvjvFxyySWZ/cQTT+jFF1/Ur/zKrxza9txzz2X7\ncF7YD94bUT84/6973esyO1qnv/jFL4ptI06TD1u8ePGk/BfHivfeSSedlNmc86iNmv8655xzDv37\n3nvv1TXXXKMXXngh2+fuu+/O7LGxscw+/fTTi37Mnz+/2NaHay1aFzt37szsibW7c+dOLVq0qPCR\nLf6L9oEDBzL75ZdfLtrgmq75rzlz5kiSVq9erYsuukhS+d1Dv/Diiy9mNudRkrZu3ZrZjz32WGbz\n2iL/NfEdMMHy5cslHfRBl1122SE/NsHevXuLNr773e9m9qOPPprZU/Ff9L0XX3xxZq9bt06SMh/2\n/PPPZ/vU/Fc0puwH2xim/7IQ3BhjjDGmgSN50/S0pP6rlaXj2wpee+01/eIXv9Brr72mE088Mfsr\nn3+5SeUTLZ8AafMNiFT+9ca/zPjXzcRfGa973esO/fv+++/P9tmwYUNmn3322Zk9d+7coh+E18un\naP71FzHxZmnfvn1asGBBMR79vzon4F8m/GuOfyHwLzep/OvtpZdeymxe28TT/VNPPaVly5ZJkk47\n7bRsH/519/jjjw/8PIJ/VbDv0bXwL5MNGzbo2WefPTTHE/2dgH8xSdL69esze+Jt2gSc26997WtF\nG3wbwDHkm7g9e/bowIED2VzwPLw2Xn90z7GN2ue0Dxw4kJ03GvMRpMmHvfbaazpw4MAh/9W/l1r8\nF/dp8V98G8W3D6ecckpm9++T4447Tscff7xWrlyZ7bNp06bMnor/Yt+51iL/xb/qJ3zv/v37deqp\npxZtsl+SsjerUt1/RfPCN030Z/QjE29kn3rqqUNv4RYuXBjuM8HEm5RBcDxq/it6A8L7b2Jun3vu\nOW3atKl4a0jfJEkbN27M7Im3aRNwbm+99daiDfov9pVv4ibeeB04cODQup+s/4rGY7L+JjpHvx+D\ntN5H8tC0UtLZKaVlknZI+m1J/zXacdGiRXrhhRf0lre8JQy3jBL8shxlGOoaVaKw5SjCV++jSu0B\n51hQc3QjSpMPW7hw4YzxX9LMud9aHtJGgShsOarYh02N4447LutT9NA9wZQfmrqu+0VK6Y8k3amD\nYb6/77pu7eH255uOUcUPTcNnpozpTHHio+ZwZiqT8WEzxX9JfmgaNjNlPCU/NE0HR/KmSV3X/Zuk\nFUPqizHGTCv2YcaYyTD675qNMcYYY0aAI3rT1MqgMFL0mo66AQq/eEwkpKRAjaJlCoyffPLJog2K\n+ihQ5HVFP+WuwZ+L05YOasL68GetjLlHomWKDXke/gQ/mhe2QRgHZptSKXClwJP9evrp8rcF/Pko\nz0PR/9KlSw/T4/8H00vw57fRT6/f//73D+wXw5LRa/577rkns88///zMvu222zI7+ok7x732Y4MW\nXQ41SbxforXeP29trcwkBoU8orHktsP9QGKC6OfxFJNzH44/f5QQbasJv1vWBddSi/+ieJr+i/fn\nhRdeWLRR818t4dNBOpXo88h/TaQhmIA/OOLP5yP/xXFm33mP88czERzT1atXZ3bkv9773vdmNueW\n/iryo/fee29mT6TumeAb3/hGZkf+qyaEPxb+a9Ba8ZsmY4wxxpgG/NBkjDHGGNOAH5qMMcYYYxqY\ncsHe5hOk1L373e8+ZFNrFKVEZ6IyxkFbtEOMYVKzwkSVEYwDU3/D2GqUiJGxUfbjqaeeyuwoNk/t\nFBO7MeZ96aWXFm1wzJh0bNeuXZm9efPmog3OA/salSYhvBbGnpnMkQn6pFLD9uyzz2Y2EwEyzi6V\nycuiMgN9ong+9Ue8fp738ssvr/aD1/uhD30osyOtENdYLWdSpFdjP7gPtRsf/vCHizb6Gplbbrll\nJtSeq5JS6t71rncdsqkdicaSY8X7dRj+i/dnlBeL9xr9F31v5IupJ6X/ZkkQniPqB8eDmqdIk8kx\n4/1K/8V+SeWY0n/RjvwXdWAcd/rVBx54oGiD/os6qEElcg533khL1mfJkiXFNvon+i+elyWdIni9\nv/7rv57Zkf+qJUwdhv/iM8WNN95YtNHXLn7lK185rP/ymyZjjDHGmAb80GSMMcYY04Afmowxxhhj\nGpiWPE39ODAL5TJWL5U5SahR4edR3gZqY2oxXxbAlMr8LCz4yDg79Q5SqTfZuXNnZjOeG+W04nmY\n64gx8ccee6xo44ILLshs6heYlygaL2oNGAPnPFBrFO1DfQM1A1GpBfaNsXnmRolybkwUPZ6AOoNa\nriNJ2rFjR2bz2rZs2ZLZkS6KuVC+/vWvZzbHh/l7pHIua3nNIu0dr585pv7u7/4us6MCoP3745Zb\nbik+n6n0/QB1jtT4SOVY1vxXpCWiNob3+OGK4PZhTiHqSXhe5rKTyvuABXmn4r/Yr3379mX2E088\nUbRB/SDvNfq8yH+xIC01TByPqI2ajpXfGZH/4lxy7uhXIv/FY/jd1OK/OJe8NuptW3RRt99+e2bT\nf0Vr7Gj4L/rVv/3bv83sWi6wr3zlK8XnE/hNkzHGGGNMA35oMsYYY4xpwA9NxhhjjDENTIumqR87\njfJ4EMYwGRf9l3/5l2objK1TixDVASOT1VZFNfAYv2ZMl3H1KIcL4+KMATOeHdX3Yf061qVinpMo\n5su8JTVtRhRHp+6LcXRqAqK6X4xpc31QaxXlbKGugrmuqIuK9A1cY4zFs41t27YVbXAdsq/UoUTx\n/EgTMwiul6iNP/uzP8ts5mh5/PHHJ3XOmUzffzEHU0RNg8G1FK0L+g2uNdabjKA/ol/g51ENPGpO\nuU+L/+I9XPNfvJ+lUoNIHRT913nnnVe0sXz58oHnjfwVoaaQ189rpf5UKq+f88Ixj9YH/Rf9+/bt\n2zM78l/8XqH/YhtRHT3WM6zpSafLf33yk5/MbOpxI91cK37TZIwxxhjTgB+ajDHGGGMa8EOTMcYY\nY0wDfmgyxhhjjGlgWoTgffEkBVsU4EqlEK4m2orEwkwkyGRgUcIwEgkj+1CkS/GmVBaWpBCOwslI\nKE8BOsXkFAFGSRQpYF27du3AczCZnFReL4+p7S+V18t9WJzxi1/8YtHGTTfdNPAYis0j4SCFoxRW\nthSW5vVzjCmk5JhLZcI9Cn7Z9yhZHu+XqHhr7XOuoTPPPDOzubajua2th5lKf165fjluUrl2nnzy\nycymsDeaj8WLF2c2k+/W5liKf5jSh2uL4mqpTFBL/8UfckRC+Zr/YsHeKIkiC66uW7cusymmjoTg\n9PmR4HzQ/tE2jjHF1NE5eH08hmLzFv9FwTnbiBJAc8w4xpz76McfTJpM/8S+R9/VvF9qazsS7POH\nXhT9D9N/+U2TMcYYY0wDfmgyxhhjjGnAD03GGGOMMQ1Mi6apHytkockojs5Cpxs3bhzYfpS4653v\nfGdmM07KfkRxUiYuYzybcdKoQG0tcRc1EpEeibooaq2YIJHxXEl66KGHMpsFLpm8kPHtqB+MxVPv\nEMWNOYaf+9znin1qsOjxjTfemNlcDyzeHFHTr0Vas8kmZYuSw/3oRz/KbBZq5RjTluraFeoZIn0D\nC/RyLnkvRMlhH3744YH9mKlM1n8xQenmzZszm8lXo2K7HG+el/4smlPewzyGfY80mZP1X5EeiX6j\nVlz1rW99a9HGI488ktnU1zB5YaRPoX+m3ojX2uK/OGYscks9m1TqrW644YbMpv+Kvpu4reYDIq1Z\nbW65plhIWJLuvvvuzKavPRr+K9I88fq4Lnk/RclhWbT+sP1p2ssYY4wx5pccPzQZY4wxxjTghyZj\njDHGmAamRdPUj/NSsxHloCCRzqfP1VdfXWxj7JQxTsazo5wcjBsz1swYeVSskv1g/PbSSy/N7HPP\nPbdoY/Xq1ZnNuDnjyJGGh7Fn6gaoK4i0GtH19aEGINJZcDz+8A//MLOjvEzky1/+cmb/4Ac/yGzq\nsyJNHHM5UQNBHQbzgEil7odzW1s/UpmnrJa3KpoDnqemf4na4JqhfuGaa67J7Ch32l/+5V8W22YD\nfY0S10WL/2LOpVqhVKlcS5wz2lEb3If+iusx0rhM1n+dc845RRtr1qzJbGq+nnnmmcyO/NdPfvKT\nzKa/opaKuX+kel4mXmvkv2oFaHlf3H///UUb1EdS00b/RU2cVPov5lzi92yU3419rxUwjvwXc2zR\n1xwr/9Uvsi1JV111VWYzz5fUrq/1myZjjDHGmAb80GSMMcYY04AfmowxxhhjGpgWTVNfB8C4eZSj\nhHlMGHu97rrrMjuKcdZyBjFeHcW7qQGo5RuJ6uqwRhBrel1xxRUD95dKDUAtH85ll11WbKOGiTbz\nFLVoJKgD4nhEmgAeE9XuqvHZz342s88+++zMZs4h1neTpHvuuSezeW1cp1EOLh5Tq5kUtcF5oEaA\n8X3WmJLqa70l/wy33XLLLZl94YUXZvZ3vvOdoo1ajciZSn/eOJasCSeVOWFqWsDa51KppaGGJcrl\nwxxCNf8VrS1qRbheL7/88symPkkq85Nxn+9973uZHY0pNUy8x6nHafFfHEO2Efkvzu2CBQsym/MQ\naauuv/76zOa88Foj/3Xvvfdmdk3zFumRJuu/oja4Hvh9zu/VKB8e+8G1PhX/9aUvfSmzmRvrjjvu\nKNqIdE4RftNkjDHGGNOAH5qMMcYYYxqoPjSllP4+pTSWUnq0t21uSunOlNITKaU7Ukrle11jjBkB\n7MOMMcOi5U3TVyR9ANs+Jen7XdetkHSXpE8Pu2PGGDMk7MOMMUOhqkDsuu4/UkrLsPljkibUbF+V\n9CMddEIhc+bMOfRviryjhGq14roUvkbUCrBSbBYlt6QIkqI+FsSMEt1RCHfBBRdkNpOUrVy5smiD\nySxrRAUvKbh+6aWXMpt9jwpecq5uvvnmgf1g4kqpnmT0C1/4wsA2JenTn86/35gQk+vnV3/1V4s2\nmDCO4lQWdOR4SWXiOib2o2g0Kky5fv36zKbgmkRJRyebHK4l6SiTCXIuo372E3VGxT2PFUfqw/o+\nq0XkXRPU8phoPo6F/4oEtvS1K1asyOyf/exnmf3AAw8UbdB/cQ3zBzRRMWj+QIL3I68/+mEP7xOu\nebYZFS2nD+R5zjrrrIG2VCZrZiJG3r9XXnll0QbHlG3wHPyekaQHH3wws1nonUk4o/WxYcOGzD7/\n/PMzm4V0IzH50fBf9913X2b/yZ/8ycB+Svl3JIvCZ+c/7CeDWdB13ZgkdV23U9KCyv7GGDNK2IcZ\nYybNsITgXX0XY4wZWezDjDFVppqnaSyltLDrurGU0iJJZXKhHv3cQ13XZeE6Y8zMZ8eOHdq/f/+x\n7sZkaPZh/dDtgQMH7L+MmWXs3Lmz2X+1PjSl8f8m+LakT0j6G0kfl/StQQf3i9C2JNRijJNx9Vps\nOoKxaMbAmWBMKuOvTIZGfVakaaKWiMnQHnvsscxmIkupjAuTj33sY5kdOXUmuuO1MI4caSpYKLdG\nNLfcxjHjtUbx689//vOZTa0G9Uks1iiVBWiZ7Iy6C861pOImW7t2bWYzbh5pzW677bbMphZh3rx5\nmR3p+WrJLGsagegYjju1dtu3by/a6I9RlNTvGDNlH9bXqk02IaBULxTb4gNrCQAj/8V7nv2gn4g0\nd9QS0X9xzW/btq1og9oYrkcW/eX+Unmv8T7gd0Dkv6iVqhU6ZzFtaTj+izog6o3Yj3e84x1FG9Q5\nMUEo/Vc0ptyHyWmZEDLSmn3961/PbPqv2jqW6sksh+G/qLWLNJd9/xVpwA61fdhPxkkp3SrpJ5LO\nTSk9lVL6XUl/Len9KaUnJL133DbGmJHDPswYMyxafj33O4f56H1D7osxxgwd+zBjzLBwRnBjjDHG\nmAampWBvXz9D/UWL7oXxasYvo2KV3IdtMJ4bFVNl3JyFJJnHI4qTMk8HtR7UHbCgr1TGzW+88cbM\npu4gytlCPUMtN0bUxjDgPPA8LeuDcJ44XtG8UG9Ejc5DDz00sJ9SmbOHc/voo49mdpQbhMf89Kc/\nzWwWUY3EipzLmuYvyo3GY2q5USLtSnQfzgb69w7XQaSn5L1ErRDHKdK91OaD/qulICv1cdTfRDnA\n6I+o9eAxzPUjlde/ePHizKa2qiVfVG2tRfcrc6Ixzxo1TJGmifNNm33nWpDK+a4V3I5yBjFfFv3X\nI488MrBNqfRfzLm1atWqzKbGKTqGY8q5HRX/xSLSURuHw2+ajDHGGGMa8EOTMcYYY0wDfmgyxhhj\njGlgWjRNfY1JS9yQ8UfGJxkjb8n9UNMEMG+RVOpJGAOmDirKx1LLa8JadFHNt7vuuiuzL7/88szm\neEVjzOtnXLimf5gKUd4X6sAYE2f8OsqPRA0Ax515TqL4NfUKF110UWZTI7Bly5aiDcbnGb+nXu2e\ne+4p2mAeL2qcqM+KNDQ1DQDntiWvGe8HrrHa3I5gnqYp05+Dlnutpq+gviTKvVXTTnHtTcV/UQcV\n+S/qOB9//PHMpk4vqtdG/3XZZZcV+/SJNCvUBnGMeczcuXOLNtasWZPZHEPqsSIdEKn5L465VN6P\nnP89e/ZkdqTJpP/i9wj9V5T/j/o0+lrmuqLeUpJOPfXUgW0eK//Ftcz1Efmv/nfvEeVpMsYYY4wx\nfmgyxhhjjGnCD03GGGOMMQ34ockYY4wxpoFpEYL3hVtTEVLWimS2JEOj6JHHRIJjFjnkMbt25YXR\nr7322qINFtKkUPLkk0/O7J/85CdFG/Pnz8/sSChZ+5xjSGElBYvs11RoEf1T1Me5jZLDsV2KPinw\njBJkUmhL0SyTkkZichYGpnCSYx4VdKZguiYSjRIhcoxqP6SI5oVtTCXJ6GwSf/fpj03LOHD8a/4r\nEqVSyMqx5fxERbr5oxKuef5g4uqrry7aoP9im/QT9957b9EG/Vf0w50+0RqnT+MY0n/xfpakG264\nIbP7hZilUvzb8t00DP/FMWzxX7X5p/+KxOSc/9nkv7jWo76TQeLvrH9NexljjDHG/JLjhyZjjDHG\nmAb80GSMMcYY08C0aJr6cU7GGiP9Ta1YbC3mGW1jvJax1uic1Bow5rlkyZLMfs973lO0ceutt2Y2\ni+tSFxPpQpgM7qWXXsrsmnYhgtdPm+MlSTfffPPAvjIBZIsuipqA2phH7dZ0JlEcnRo3JvE744wz\nMjtKlsfkppwX6g6ifnDumBCT4xNpV2rnpV6PCfmivlEDwM+jaxnUh5lMX0NRKwQq1YtS85jIB9Z0\nTy3+i3PIeWdi1euvv75o47bbbstsJjOkLibyX5deemlmc70yMWdL8kJqZ2hHOrHaPf7UU09ldqRz\nrWmaeN5obqm3qml2Ig0PkzNTN7Z06dLMjvwXfSB9PtdPpEWj9o5ttvgvrkuu5VphYam8p2q+t6ZX\nG+S//KbJGGOMMaYBPzQZY4wxxjTghyZjjDHGmAaOecHeKI8FY7yMi9byFEmlNoS05BCq5am47rrr\nMrsl38rY2FhmszhjpANifLUWa27RWTBfFD9njiqp1BcxtlzLpRJRy6/B2L1UXt8f/dEfDTzHZz7z\nmWLb5s2bM5vjQY3AihUrijaYw4Z95RqjlkOq5zWhRiSalze/+c0D+8E1GMXrqffgOuWai4qu9vUu\n3/3ud4vPZyqDNIJT0TTVcqZJZa6eWsHaqI2a/7rmmmsyO/Jf1BtRg0ldX+S/eP013U80pvQltdxX\nkf6G9x9tnrdFW8VjpuK/avmSoiLu1F9xH/ov5qSSyrmbiv/itXC98DuCvkoqfe9U/Bevl+t0sv7r\njjvuKD6fwG+ajDHGGGMa8EOTMcYYY0wDfmgyxhhjjGlgWjRN/dgo46SR7oXx6Fp9n0hzQP0N46CM\no0daEcaWmaOEceJNmzYVbTCGyzapi2HuEKnUAHB8OKaMAUdt1MYjqtXDY2hznqIYODU7PKalVtFN\nN91UbBtEdC0XXXRRZjPH1MaNGzM7mpeLL744s//zP/9zYD9acpLVcrRE9wvzyTCvSTQPhNqpWq6v\nz3/+88W2efPmHfr3bNI09WnJEcd55ljWNJvS0fFf1K2dffbZmU2dn1TqTdgmdTHMDxQdU7vHI//F\ne7g2Hi1592r1FaNcdewb9+HnkXaWx6xduzazea0XXnhh0cYFF1yQ2dQ4cS6jeaEPfPDBB4t9+kTX\nUtOttvgvrl1+Z0ZaO8L7pea//uqv/qrY1s9lZU2TMcYYY8wR4ocmY4wxxpgG/NBkjDHGGNOAH5qM\nMcYYYxqYFiF4X/hHEVwkjq0V12MbkbiM4jEew2RYUQIxCmgpLlu1alVxDGGiLoq4ly1bltlMDhZt\nYyK7mrg62lazWxKZ1ZJbRnCueJ5assep8NnPfrbYdvvtt2f2+vXrM3vlypWZHSVUW758eWYzUSl/\nGBAlIOSaqhXfbRH5syg0108krq/NA8Wa//iP/1i0ERXSnA30x4LzEYljOUccb85XdL8Ow3/VEseu\nXr06s6NrYZJN3uOnn356Zrf4r8kmqpTqCUJr95FU91+1ItRSOaZsg/MW3a+Evuexxx7L7Gg8Lr/8\n8symr+GPUqIfw9T8F8XlEcPwX9yHP7ji2m8R13N9UFx+6623Fm20+i+/aTLGGGOMacAPTcYYY4wx\nDfihyRhjjDGmgWnRNGUnrMSiI2paGSa2kurJz2hHicxqepoHHnggs9/1rncV+7CAJePTCxYsGPi5\nVGoCasm+hlFosiU5HNuotRn1jfFpJstrSWw2FX7zN38zs2+++ebMplZj3bp1RRuMvS9ZsiSzeS3R\n3HLt1jQQLYn/2GaLVoNJDJkgk0TJK1v0GzOdFv/F+aiNf6SlqPmvms5TKv0X9TgPP/xwZl977bVF\nG0ycyjZ4D0RrnOsi0tf0aflOqBXXjfrB83IMW/wX22Ubzz33XGZH/mvHjh2ZzbnlvDH5pSR98Ytf\nHNgv+qInn3yyaINzt3jx4szmtUTfK1y7te/M6HPOS01rFmmaqFmi/+L43HnnnUUbrf7Lb5qMMcYY\nYxrwQ5MxxhhjTAPVh6aU0tKU0l0ppTUppVUppU+Ob5+bUrozpfRESumOlNJJR7+7xhjTjv2XMWaY\ntGiafi7pT7uuezil9BZJD6SU7pT0u5K+33Xd51JKfyHp05I+FTXQj0lSOxHlv6nlQqHGh7mQeE6p\njKWyTeYjkcp4/pw5czKb+gbGgKUylsp8N+wHxydqg9dGnQH7FW1jrJ3j0xLPZ5uMzbfki+J5OPe7\ndu0q2jjppPz7jcV0qSO7++67izY4hiy+TDvqx9jYWGZTR8DYPOPuUT+Y54TrJRpTzkMtZ0m0PmoF\nUdnPqI0WLcox4Ij9V/9aucYj/8WxrGlWIv1NzX9x/Fv8F2228fzzzxdtkJrWLfJfLf6p9vlk/ddU\ncj21FGOu5bfjenjmmWeKNlgMnPrJd7zjHZm9ffv2oo177rkns88666zMZjHmqB/0aaeddlpm0xe1\n+K9arqMoV13Nf3FuI11ULXfjMP1X9U1T13U7u657ePzfL0haK2mppI9J+ur4bl+V9OtNZzTGmGnC\n/ssYM0wmpWlKKb1V0qWSfippYdd1Y9JBxyRpweGPNMaYY4v9lzHmSGlOOTD+avsbkv6467oXUkp8\nz1a+dxtn8+bNh/49b948zZ07d5LdNMaMMi+//HL4s/dR4Uj815YtWw79e968eUX41xgzs3nllVea\n/VfTQ1NK6fU66HC+1nXdt8Y3j6WUFnZdN5ZSWiSpFH2Mc+aZZx76d0t9Mup8GGus5QuK4D7MyRDl\nsSDMY8IYbxQTreWHYuw1yutR0w4xThzlsajt07JgqK9pqQFY6wfHjPPEc0plPhHqLC688MLM/rVf\n+7WiDeqiuB7Yz0irwdpMtZw1Ubyff0DUcsVEbXA8qL1jvijWmJJKHQ6vv5afhrXPXnjhheIcx4oj\n9V/9Gl21+1cq55A6F9o1jU/UJo+JtFWcdz7s0Y78Vy0XG5mK/6rpTyJG1X+xX5EOiNoh9uv888/P\nbN7PUjm39F+8lsh/bd26NbNPOeWUgW1E9fy4hmr+K2qD/ovaO14rbakc98n6rxNOOCE7ZpD/ag3P\nfVnSY13XfaG37duSPjH+749L+hYPMsaYEcD+yxgzFKp/4qSUrpX03yStSik9pIOvsW+S9DeS/jml\n9HuStkj6raPZUWOMmSz2X8aYYVJ9aOq67h5Jh4upvW+43THGmOFh/2WMGSbOCG6MMcYY08C0FOzt\ni65qyQwQv4LhAAAgAElEQVS5v1SKumpCy+g8FOStWbNmQI9jKKabP39+ZkcJ5iiQrQnlIhE3t9WE\nky1FRJkgtEVMXivqWxPwt0BxZiQKpWCRwkGKIikMl+pJCjnXUeLSlStXFtsGcf3111f3aUnSR7gP\nhfF79+7N7KgwJced64H3T5Skrr+mdu/ePaDHMxeukxbxdE2EGhWwZdJErleOb0shZ65p/gghKnwe\nCYj71AoLS+UY1XxNlMCV1zKV4tDsR62weYv/4rW0/EiJ3xu8X+kDKAyX6mPG+zVKXMr55vVyzOln\npXri0mH4Lwq/o+SWtYTPk/Vf0Y9lDp3rsJ8YY4wxxphD+KHJGGOMMaYBPzQZY4wxxjQwLZqmfpy3\nVvSV+0tlvLYlBs7zMAbOeH6UMOuaa67JbMb3ed5Im1BLXDeVeD51UrzWqA0eUxvTSJvAxGQtBXpJ\nra+0o2R5jGl/5zvfGXjO3//936+28YEPfCCzFy5cmNn33XffwHO08OMf/7jYxvNyvVB3EBVMZcLL\n1atXZzb1DEzsGZ2Xc8tjIv1LPwnfhg0bis9nKv37r6X4LO/Xmq6jpbA11yuT7y1atKhoo6bjYL8i\nbSjXAbUjLTpGXkvNF0XjRf9d8zUt/qumg4l0nTX/VdMFSeVcUnPIftEXSaUmlXrJBQvyqkD3339/\n0Qb9ApP1UnsVVfJgXznu9E1RsmLuQ73xvn37MjtK9skx5dxRjxUl2ezvw6LKffymyRhjjDGmAT80\nGWOMMcY04IcmY4wxxpgGpkXT1I8DMyYc5UuItvWp5XGKzkMtCOPq73znO4s2uA9j/szlUMtpEvWL\nsdjatUf9qLUplbFn5uVpKaTMfTgPLYU2qQFhbJmagEgzctddd1XP0+dLX/pSsY16NeoGqNm54IIL\nJnXOiBtvvLHYtmnTpszmGHJ8WNxSKvUtUxlTamJqOpwWvcdsYZD/qu0v1e+TYfivSOdRK+pL/xXp\nTWrUiodL5fVHOsU+kf/itdT8V6R5qulveEzkz2rHtLTBfXj/PvPMM5l97733Fm2sWLEis6lhok7o\nvPPOK9qgjpd+44wzziiOITX/xXmKtHf0tVPxXywcXHvOiOal1X/5TZMxxhhjTAN+aDLGGGOMacAP\nTcYYY4wxDfihyRhjjDGmgWkRgg8SCFMoJpVCL4oeKXKLhIVM7EZxIfs0b968og0m+2JCMZ6DtlRP\nIsmkbS1FIpkwjeMVFbOMhLt9Wor+st2awDUS1tWuj2LVKJnjFVdckdmTLZwrlcLAf/iHf8hsznVU\nNJOwMPAll1yS2ZEY8+mnn87sxx9/PLOZVJL9kspr4Zo79dRTMzsSY/JHDBQJU6wZ/eghShg3G+iv\na675yH9RLMz7cyr+q5Z8NEo8uHXr1szm/cu1Fc1pTdhc8wlS6XujJJqD9o+oJaJs8V+kxQfWfqjD\nYyJxPe8tJpmsFZuVSt/6T//0T5lNP0HhuFSOGed/6dKlmR19R+7YsSOz161bl9lcY/wul8rklVxz\nLNAeJftk35kwlGL7qB/RvRzhN03GGGOMMQ34ockYY4wxpgE/NBljjDHGNDAtmqZ+rJDx6ijmW4sb\nP/LII9VzLl++PLMZv2WsNUruyLgn+zqVhJA1omuvJfd67rnnMjvSFTDGzZg47ZbkXzV9Usu11wqT\nRuMxFQ0T4XkYV2ffqUOQpD//8z/P7IsvvjizqT2LCuVSZzGVpJK1eD7PEWloeP1sg2s/mvtIJzAb\n6Psv3nuRDqimt6kVzpXKAqNcjzxvdL8Ow3/VEta2JOOt+S9qeqJzcg3zvLSja6v5PNKSmLJWgD4a\nH2qU6Bf4eXTPczz279+f2dTN8X6WSq3jRRddlNkt/qv2vdKyPibrv6IiyLx+tsExjea+1X/5TZMx\nxhhjTAN+aDLGGGOMacAPTcYYY4wxDUyLpqkfK2ScOIobt+TLqMECfow1t+T1YI4gxsmpi4nipLU8\nJ8wNEbVRy3/EmG+U54Q5dGpttmir2AavtaUNxqcZV47m5UMf+tDA8/CYqHgnY9zz58/PbMbvozaY\nB4dxdRbEZCFOSRobG8vsWgHUqB9cp9TDcO1H/WAeE84L9TBRTpOWAp8zkb5uo1a0OtrGe4uasih/\nEAvw1vRH0X1S0zDRHob/iu752nl4/dG18jwc4xbfQ2rfAVE/eB7eJ9TnRPqbWj4k9iOaW2qJmMuI\nPiBqg/6LOihqZXfv3l20MVn/Fa0xjgf9WYv/Yh45jjv9faTr5DwcDr9pMsYYY4xpwA9NxhhjjDEN\n+KHJGGOMMaaBadE09WPWtZwl0T6MZ59++umZHeV6YpyUWhnGXqN6SIylTrafUhnDZWyV/bj99tsH\nnlOSPvrRj2Y2ry3SWbTElmufTzbfTNQGY8kcd85bpCvgMbU6g9SHRP1gXaWrr746s++8886iDdZZ\nYk03agCia+H1sh9TyQXGOmRcl9QvRVBXwHssuueiPC6zgb5+pKalkUrdD/WEtKO6caSmW4w0KzX/\nxXUT6Tx4fZz3Wi06qdSXcD3WfHPURs1/tXyv1Ijmln2vaTKj3D81n8d5i+4rzhU1vFdddVVm/+AH\nPyja2LhxY2YvWLAgs5mbriUXGNdyi26O18tr4ZhTvxTBdVrzZ1L8PRHhN03GGGOMMQ34ockYY4wx\npgE/NBljjDHGNOCHJmOMMcaYBqZFCD6ISMDIpFo7duzIbArSIgEXxWMLFy4ceI5IJEixJUV/NYFj\n1NepJOokFBJSSEehqVSKGmvJPlsEyBQjtiT+4z618WESN6nsO8WnPCYS2vI8Z5999sB+RqJaiiCZ\ndI3niESy7CuLl3LdUiQplcJI9ov3T5Rwj2J6JsejSDQqVNsiMJ9tRPczix8zASDvC461VPqSc889\nN7Nb/BfXcC2xbOS/2AaPoY/csmVL0QbvizPPPDOzj4b/aoHXUitOHJ2X/WrxXxxT+gXa0T3P83JM\na4lMo75xnmqCdakUWHPt039Fvrjmv3bu3JnZkf+qCb9ZnDgS6Lf6L79pMsYYY4xpoPrQlFI6IaV0\nX0rpoZTSqpTSZ8a3z00p3ZlSeiKldEdKaXb+3tgYM2Ox/zLGDJPqQ1PXda9Iek/XdZdJulTSh1JK\nV0r6lKTvd123QtJdkj59VHtqjDGTxP7LGDNMmjRNXddNVPI7YfyYTtLHJF0/vv2rkn6kg46ooK+p\noA6GRU2lMrbIhFhM9hUlZasVD60Vn4221ZI5RgmzatqgWpK2iFoCyOhaaoU3W+L5jHEz9t6S+K9W\n9JhtRPHrmq6A/WyJVdcSDEa6gmXLlmX2fffdl9ktCfne+ta3ZjbHg+MV9YPbVq9endm8/qigM+E+\nLEa8ffv24piWpHPHgiP1X31NRYv/4jhw3qnBjNY4E/jWilJHmp5j4b82bNhQ7EM/Qf1crXi4VPdf\nLZqmmh6rdk6prhViv6K5rSV85NyykK5UzmXkF2qfc42tXLkys+lHo3mhD6RvriWulMrv87Vr12Y2\n76do3jge1GsN0381aZpSSsellB6StFPS97quWylpYdd1Y+Md3ilpwaA2jDHmWGD/ZYwZFq1vmg5I\nuiylNEfSN1NKF+rgX2vZboc7vl9O4vWvf32owjfGzFyef/75omzMqDBM/3X88ceHv7wxxsxc9u3b\n1+y/JpVyoOu6fSmlH0n6oKSxlNLCruvGUkqLJO063HGnnHLKoX9HoTRjzMzmpJNOyl7F82f2o4D9\nlzEmYs6cOVnYlOkX+lQfmlJKp0h6reu651NKb5L0fkl/Lenbkj4h6W8kfVzStw7XRj/OXYtNR9sY\nE2dMmDkZpNzRSdLTTz+d2cyNEsVJGQetFc3kOaUynwqfZplfowX2oyX3E/vKGDDnpUUjwHmq5SyJ\nzjvZoqJRGzxPzZbKNbN+/frMvuSSS6r9YF6b5cuXZzZj89E6Peeccwa2yXVLWyq1Cewr34xQUyKV\nY8S3wVw/kb5hFN8gD8N/9Qubtvgv3jscf675aD5YuJm5tui/ovuopmWjPX/+/KIN5g1jEVdqWpjP\nSyr1gjVNYkvOPPoA2i3fKzxPS8FxbqMvZj9a8t3x3qOWqMV/sfju2972tmo/+AcA9ZVPPPFEZkea\nt7POOiuzp+K/lixZktmcF+qTon5wDfGeq60fKb4PI1reNJ0m6asppeN0UAN1W9d130kp/VTSP6eU\nfk/SFkm/1XRGY4yZPuy/jDFDo/rQ1HXdKkmXB9v3Snrf0eiUMcYMA/svY8wwcUZwY4wxxpgGpqX2\nXD/eWNPSSGXsmbH2RYsWZXb0axbGzRkXrdWVk8qYby0XRKSLYgycGifmhvjIRz5StMHx4Hk5hlEs\nnnFijg+PiealxlRyPTGO3LI+SK2GVJSnieOxbt26zKY2g9oOSdq2bVtmU5/GdUrNgFRqU6gZYc0k\nal2iNjiXLfo06vc4huwH5zE672xhsv6LfoBzxnpckf+q1SPj/TsM/xXpoqin4X3AOnG1/HhSPS/R\nVPIjkWg8av6p5T5hX2u/pGy5J5iHif1syR/05JNPZjbvV9aEk0r/RU0m/Re1k9Jw/Fek9exDbVUE\nfTzHkHrjyH+1fuf5TZMxxhhjTAN+aDLGGGOMacAPTcYYY4wxDfihyRhjjDGmgWkRgkeJpCagkEwq\nk13RrhWslUohGAsFUnzXL8o5AYVwPIbiuig5FpN9LV68eGAb0bVwjGpJ2qI2KPJkv1raqIlgKa6L\nhKW1pHRsk/2M2q0lh7v77ruLNibLe97znmIbi7VSjEmiHwrwhwGcB9os9iqV4luKLyn43Lt3b9EG\n7ynOA8WokXgzanc2MMh/ReNAf8V7nuLhlgSI9F8UYEcZ2Ck45zEU/0f+i4Jq+kQKw6N7nmNUKxYe\nCbY5RvQLPKblRzk1QXrUj1oyXt43UQb5ySYFjnwgx537cD1EImf6HibIJC3+q7aWo+97Csxriakj\nP8N7itdLoXiUIDMqvh3hN03GGGOMMQ34ockYY4wxpgE/NBljjDHGNDAtmqZ+nJPJrVjwTyoLPDKW\nyth8VCiUWqFavDKK51PLwDgoY89M7BXtw4Ry1KxE+glqdGpJ2KK4ci3JWksSNuob2Ff2K0ogVtMj\nTaXgJWlJsjlZfvjDHxbb3v72t2c2Y+9cl1y3Upx4sw+1LFEyPZ6X98vSpUsze9euXUUbXP+cF+r5\nIm0C9S6zhf4apG+KCm5zzjgfHMtoTum/ouSqfSIfWPNfvJ9ZTFyqF6jl/Rn5r5aC4n0i3dCx8F9R\nm5P1Xy2+qKZjjPRI1Cny2lgsnIkrpXKdbt++PbO5LiNtVS3xZksiVxaj5hhTIxj5r9p3M/seaUNP\nO+20YluE3zQZY4wxxjTghyZjjDHGmAb80GSMMcYY08C0aJr68VQWLY20EdTCMKbbEiemboAxTsZA\no/g1z8N4LOPIPGfUBmOr1DtQ8ySVfa/lCol0QGyjFkeP4PVTo9MSz6+dp2VumfukpXjpkXLFFVcU\n2xivpyaA/YhytrCNzZs3Z/aKFSsyO8qVsn79+szm/J900kmZvWbNmqKNSy65pNjWh32P7tuob7OB\nZcuWhf+W4jxNtQK0nJ9ozdf8V63QdXQe6pF4L0aau9o+nPNIs8K+13SKLZpMjlmLpom+lb54Knok\n0qLBpF/gMbW8TVJ5P3Ie6BOpX5LKfG7UFvF7ONI0Uce4ZcuWzD7nnHMG9lOSNmzYkNk1/xWtsckW\np47u29r36gR+02SMMcYY04AfmowxxhhjGvBDkzHGGGNMA9OiaerrMhhXj3L5RHkp+rTob2q1tPh5\n1A/CfVryj9SuhfHtqM2aVoSft+izeAyvrSU2/2//9m+ZfeONN2Y251qq52HieLTUf5qKPmuyRBoe\nXgtj7ZxL1vqSSs0SNSPMxxLl62G8njlI+Pn73ve+og3mi+K4U0PDmlOzmXPPPffQv3nfRPcr7/lh\n6Ad5f07Ff7GvLf6rphXieVtyG9Ev8PPIZ3I91nSMkd/gNt6/7HuLRo/+i9qayI/WfGtLHT3mC2Ne\nL/qrSMPD66Wf4DxEml3qjbgPdZ7sZ3Re9p2fR/osakE5xvRfkR9t/d7wmyZjjDHGmAb80GSMMcYY\n04AfmowxxhhjGvBDkzHGGGNMA9MiBO9DoViUlK2WyKwlsRnFcxR5UQQZFbxkMi+KHmvJL6Pz1ASb\nkViY7TIxJ8cwSu5YE7lxvCIx5je/+c2BbdSElodrd1AbUb+5T03kf8011xRt1BJg8rwUXkZQbNmS\nlJTFJzkPFCxGAlcWmmSBXl5rJKSsFefcu3dvZkdC8KgI5myjltBVGo7/oliax3BttST8qyUJjtqo\n3Sfse1SAmkLeWmLOyEfWCptzvKIx5Zpmmy0/fqkJ49lGi/+qCbIjwf78+fMH2rV+RdB/1ZKyStLY\n2Fhmcx5afjDCBJn0X1wPx9p/+U2TMcYYY0wDfmgyxhhjjGnAD03GGGOMMQ1Mi6apHxdn/LZFj1Sj\nJQbOmCfP21IUkTAJV6TXYbs//OEPB7Z59dVXF9tq49FSELOmaWqJeZMPf/jDmR0lsyQ1vQfn6cUX\nXyzaiHQkk2lTKnVPjGdzLqM5YGI36jlqxZmlUsPGwsAsxstkcVKpCWC8njrCKHbPJJubNm0a2CZ1\nKVJbgsWZyCA/0JLMsUbLuNX8V+R7anqkmoYlOs9ktYBS3X+1aGcmW+i7RUtUS7QbUevrVPxXTVsV\n+S9uq/mvaE3Sf9EXca6jNuhbLr/88symH6EGSir9F3WcPEeUaLifgFYqCwc/++yzmR35r9ZC737T\nZIwxxhjTgB+ajDHGGGMa8EOTMcYYY0wD06JpGhQrjuKkNd0LY8CRJoC5LmhTfxLpFngexlJbdFHk\nhhtuyOy77rors6PCioxf1/Q2tVwiEbUcVJL0kY98ZFJttBRArBW8bClgXNOQRGPKMaQmoCUfD8+7\ncOHCzN6zZ09mR/fBsmXLMvu8887LbGoAIk3T1q1bM7u2HqKcU2effXZmU4vBeH+U16xl/c9E+vPM\na4z0OjXdC++tSEvBdqkX5PxQPxedZxj+i36UROuilneI91F0r9WKHvNaWnxPLXdf5AMJ96H/ir6b\nOLe1nILMyyeV18u55Xpo0d5RW8TcRpH/Ov300zOb2kj6r6effrpog9tq2rIoT9OZZ56Z2bw/OC8t\nORUPh980GWOMMcY00PzQlFI6LqX0YErp2+P23JTSnSmlJ1JKd6SUTqq1YYwxxwL7L2PMMJjMm6Y/\nlvRYz/6UpO93XbdC0l2SPj3MjhljzBCx/zLGHDFNmqaU0lJJH5b0V5L+dHzzxyRdP/7vr0r6kQ46\nooJ+XLelPhlpqdVUO4Zx0pacHIx7sk3mronarLXBXEdRLL6Wh6klv0StJtJUNAA1ormt1Y1jP6Oc\nQozX1zQStXp3UZsk0iaw3TPOOCOzqWmKzsGYP49pqd305JNPZjbHg3WpIq1GVPOwT0sOrlHVNA3T\nf9VqoEVwTXPdRG3U/NVU/Bf7zjmP2qQeqea/I19U04G15KlqyeU0mc9biL5n2C734edRTiGOEa+/\npY4eqfmv6N7kmFKfRE1TpPsdhv9iLjr2dd68edU2opqHfWpavOi8h6P1TdPNkv6npP4dsrDrujFJ\n6rpup6QFjW0ZY8x0Yv9ljBkK1YemlNJ/kTTWdd3Dkga9aqj/yWWMMdOI/ZcxZpi0hOeulfTRlNKH\nJb1J0okppa9J2plSWth13VhKaZGkXYdrYOPGjYf+PW/evKbXbcaYmcP+/fuL8gcjwhH7r34piLlz\n54YpG4wxM5f9+/dr3759TftWH5q6rrtJ0k2SlFK6XtKfdV3331NKn5P0CUl/I+njkr51uDb6ORRa\ncl8YY2YWJ554YpajJ6oxdSwYhv9avnz5oX9PVtdnjBl96L+eeeaZw+57JMkt/1rSP6eUfk/SFkm/\ndbgd+8K2WuLKFlocF8V1PG8twZhUFjTcvXt3ZlMYF4mWKZTk9baI3LmN10bhc0thxahgYa0fvBbu\nw8R2LQWMSS0RoFRP3sjPo37wPBQS8ryREJrHUPTJc9SKNUvSZZddltkUMEaJ7ijYZHHKtWvXVs97\n7bXXZjbHlGuqZV5GnKH4rxbBca1Aa8uPP2oJbaOxpz+q/TAhEi1Ptu/ReEw22Wd0rzFZYW2ttYin\n2S/6r8hXsd2af4/Go+a/Wn7IwnGnf+fn0XjRfzEJMK+F55BKUTttzmXkv+ivKB7n+ESid/rJWjHm\nyH+1/NhFmuRDU9d1P5b04/F/75X0vskcb4wxxwr7L2PMkeJYmTHGGGNMA35oMsYYY4xpYFoK9vaT\nqDFuGsVaaxqeFs1KTXvAeHWkK+B52HeKXVuSY9Vi4C0MQ1dBm3H06Fp4DOPILVqNyRYXjhLfsd1a\n4rLoHLVx5/VHBR7ZN64HJrtsgWss0gAQag1OPfXUSZ+XOgKOD/sRjflUCkXPBPraD45DS8Hxmv9q\n0c4cDf+1a1f+g8Fo/niemlakBfrrlmSOk/Vfkd/gMRyfFl/M89Q0utHcDsN/1ZJs8rzRObgPxc9M\ndllLgCuVa6ymnZXK4uj0X1wv3F8qdU6cB/YjGo+WRLWS3zQZY4wxxjThhyZjjDHGmAb80GSMMcYY\n08C0aJo2bNhw6N+LFy/OPjvllFOK/Rlrpp6E8duWYny1QpORNoG5QahR2bp1a2Yz30R0DOOx7FfU\nD8aeW+LmhDlbmGOqpSAmtQccQ8aVW/Je1OalRTNBjQDbjPQNNc0SxyMqVlnLSzUVvVotH1KkAVyw\nIC+bxvvjqquuyuyouGXtvLwXovGoFQ2dqfQrGixatCj7bCr+i+sk0suRmmanxX8tXbo0s7dt25bZ\nkf9asmRJZte0I1E/SE2fFUH/VSvaPRX/Rd/cmrenz1T0plPxX5PVhUWFlGvrkv047bTTijaog+L8\nt+RHooaJfaeWair+i3MbjUer//KbJmOMMcaYBvzQZIwxxhjTgB+ajDHGGGMamBZNUz+2/tRTT2Wf\nRTkX5s2bl9msicRYbJRfgXHRWtw4irUyd815552X2cuWLcvsVatWFW1Q38DrpR6rJVdKLVdIpHvh\n9ddyUkT9YI6aW2+9dWAbv/Ebv1Fsi+a7T0sdPcaja3HzqWiLqBFoybfCMWP+pD/4gz8o2ujr/aTy\nWhjPjzQSka6mD/sexfOZX4XHsB9RGy3alJlIfx6pA4p0EJP1X1GeuVrNt6n4rxUrVmQ28/CsWbOm\naIP3QU23GF0LmYq+dLJE/aAGkddSq5sWHUPY9yh/FjVKHI+WfHekpi2bSg5BXmvkZ+gX2Nfnn39+\nYL8kaf78+QP7xfGKNF6cW/riffv2ZXZLbsfD4TdNxhhjjDEN+KHJGGOMMaYBPzQZY4wxxjTghyZj\njDHGmAamRQjeFzvXipxKpYCRIq+5c+dmNoWXUini43n37t2b2QsXLizaqAl7KYyLktTxGAp5KZyL\nRG6kJqSMqLVbKwAplUnFfud3fmfg55E4tSZirxWejKCoj9caJT9lP2ri8oiaoJP9ikSkFEFSsMhj\non7t2LEjs3m/cI1FBX05RrwH+Xkk6OxvW79+ffH5TKXvSzjnTO4nleLXmv86+eSTB55TKu8D+q9o\nTukXpuK/uP5qQucWMS3XMO+TSPhc8wO1NqXSP9V+/BDB6+cYT8V/8ZiWJMH8sQ/91zCSJrPNaF74\n3Uv/xTai8di5c2dms7gu5zb6vufaZaJWfh6NR/88g/yX3zQZY4wxxjTghyZjjDHGmAb80GSMMcYY\n08C0aJr6MduapkUqY7pMiMh4PvUXUlloMiowWmuDWgQm8qoVr5TKvrPwJDUS0XgwlsxraRnTmqap\nFquXyuulzoVx4yh+zfh8LfEkdRjRMbXkntG1cxuPadEmcBuTf7KNKI7OxIdcY7XPpXI9ULvBMY8S\nU3Kf2jHRvE0liehMoH8vHA3/FWk0WNg8mrM+1JJIw/FfLPp70kknZTbvgUhLNFn/Fd1rNd1TS0JM\nXi/91VT8Vy3xZKRjrOnAanrLqG/D8F/UErX4L56Xa4y6Ma4nqbw/uM9U/FftO6BFb3s4ZqeXM8YY\nY4wZMn5oMsYYY4xpwA9NxhhjjDENTIumqR8/rBUnjLbRZkxzz549RRvU5DC2yth8FItn7J35cBgD\njXKlMKbN87Tob5ingrFo9pNahug8jAG3tMHYM8edOozoWjhmHA+uD8bZpfL6uT54bcybI5Xx+lpe\nppYcXBxDar4iXR3XJa+X6zjK2cK+UxNAjVM0L9TE1PQdkVajJbfVTKS/vobhvzj+zCkTwXXR4r/o\nJ5kPh2spKsg6Hf6rpjWK2uA+LW3UtGWLFi0a2M+oHzWtVeRHa7mb6Deie63mv9iPaDzoF7he2I+W\nQrm0W4oxs681jVPUj5qOk+MVFY5v1WT6TZMxxhhjTAN+aDLGGGOMacAPTcYYY4wxDUyLpmmyMA5K\nm3H0KJ5PHQtjmNSXsAZYBGPgCxYsGGhL0saNGwf2ldcS5UdirJXH1DROUj3WzLg59UlSGUveunVr\nZlMTEOk9ahqdlvwiHA+2Qa1R1I9IazDZfjAvE3VBPG+k+eGYUuPEa6GWJWqjVlMq0jfUdCact5bc\nV7+s1PxXS66nmv+i/iTK9cR2qZ2iBjPSZG7atCmz6b9a8rvxPqD/aqm/yfu1Vq+Nvihqd9u2bZlN\n/x1pXGrfRbVamlJ5vdQOUcMT9YPH1OqPRv6LvoY5lmq1NKXy+tkm121UZ7FWn642XtExbJPz0JL7\n6nD4TZMxxhhjTAN+aDLGGGOMacAPTcYYY4wxDfihyRhjjDGmgWkRgqeU9Oqrr+oNb3hDVfQllYJZ\nis1IJIKrFYGkaHdCSPjSSy8dEh1StEaRGwW1kciNomxeC8XEUfLCw4n8du/erVNOOaUQSUbJ0NgP\njjHbiJJ/UYS8efPmzKaQcGL/sbExLVy4UFIpbK4J9CIhZU1IWxNrRtteffXVQ+MptYkguQ/HkGMe\nCUlBaoQAAAUjSURBVDprCTHnzp2b2S+99FLWz+haaPMHDFHRTI4h1zpFtC3jMVvo+y+OQ0syx5r/\nitZ47ccevNf66+jll1/WG9/4xsIf0dfUEmZK5f1Iv9Divw7Hnj17NH/+/KIfke+p+a9askupvD7+\nkIUJEieKq+/ateuQSLz2I5OW+4RjFO3Tp6VQ7sQ8TYwp+1UTikul/+IYRnPL9cF9uAYn2uz7MF5f\nzX9F64P3ENdUy3PHyCW3rFXpHhWim21UiTKhjyJjY2PHugtN7N69+1h3oYmZ0s/ZxEz6ZeBM8WH8\nMhxVdu3aday70MxM+U6YKf2MmJ1/GhpjjDHGDBk/NBljjDHGNJBaYp1HdIKUju4JjDEjSdd1ZVbR\nGYb9lzG/nBzOfx31hyZjjDHGmNmAw3PGGGOMMQ34ockYY4wxpoFpeWhKKX0wpfR4SmldSukvpuOc\nLaSU/j6lNJZSerS3bW5K6c6U0hMppTtSSmXykmkmpbQ0pXRXSmlNSmlVSumTo9jXlNIJKaX7UkoP\njffzM6PYzwlSSsellB5MKX173B7Vfm5OKT0yPq73j28byb7ORuy/joyZ4r/G+2QfNvw+zir/ddQf\nmlJKx0n635I+IOlCSf81pXTe0T5vI1/RwX71+ZSk73ddt0LSXZI+Pe29Kvm5pD/tuu5CSddI+h/j\nYzhSfe267hVJ7+m67jJJl0r6UErpSo1YP3v8saTHevao9vOApHd3XXdZ13VXjm8b1b7OKuy/hsKM\n8F+SfdhRYnb5r67rjup/kq6W9N2e/SlJf3G0zzuJ/i2T9GjPflzSwvF/L5L0+LHuY9Dnf5H0vlHu\nq6Q3S/pPSVeMYj8lLZX0PUnvlvTtUZ57SZskzce2kezrbPvP/uuo9Hnk/dd4n+zDhtPPWeW/piM8\nt0RSP1/9tvFto8qCruvGJKnrup2SFhzj/mSklN6qg38B/VQHF91I9XX8dfFDknZK+l7XdSs1gv2U\ndLOk/ymp//PRUeyndLCP30sprUwp/f74tlHt62zD/muIjLr/kuzDjgKzyn9NS+25Gc7I5GRIKb1F\n0jck/XHXdS8EOWSOeV+7rjsg6bKU0hxJ30wpXaiyX8e0nyml/yJprOu6h1NK7x6w6zEfz3Gu7bpu\nR0rpVEl3ppSe0IiNqRlZRmZdzAT/JdmHHQVmlf+ajjdNT0s6o2cvHd82qoyllBZKUkppkaSRKDyU\nUnq9Djqcr3Vd963xzSPZV0nqum6fpB9J+qBGr5/XSvpoSmmjpP9P0g0ppa9J2jli/ZQkdV23Y/z/\nz+hgaONKjd6Yzlbsv4bATPNfkn3YsJht/ms6HppWSjo7pbQspfQGSb8t6dvTcN5W0vh/E3xb0ifG\n//1xSd/iAceIL0t6rOu6L/S2jVRfU0qnTPwKIqX0Jknvl7RWI9bPrutu6rrujK7rztTB9XhX13X/\nXdL/0Qj1U5JSSm8e/wtdKaVfkXSjpFUasTGdxdh/DYeR91+SfdiwmZX+a5qEYB+U9ISkJyV96lgL\nuXr9ulXSdkmvSHpK0u9Kmivp++P9vVPSySPQz2sl/ULSw5IekvTg+JjOG6W+SnrbeN8elvSopP81\nvn2k+ok+X6//J6IcuX5KWt6b91UT988o9nW2/mf/dcT9nBH+a7yv9mHD7dus818uo2KMMcYY04Az\nghtjjDHGNOCHJmOMMcaYBvzQZIwxxhjTgB+ajDHGGGMa8EOTMcYYY0wDfmgyxhhjjGnAD03GGGOM\nMQ34ockYY4wxpoH/C8AGEUFtMDVfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8cacf106a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "# We display one axial slice\n",
    "Z = 13\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow((np.clip(mask[:,:,Z]*255+im[:,:,Z]/2,a_min=0,a_max=200)).transpose(),  cmap='gray', interpolation='nearest')\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.imshow(im[:,:,Z].transpose(), cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
