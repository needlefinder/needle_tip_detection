{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/preprocessed_data/tips_10-10-10_1.00-1.00-1.00/\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from __future__ import division\n",
    "# import joblib\n",
    "import glob\n",
    "import os, re\n",
    "import numpy as np\n",
    "import nrrd\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics, decomposition\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "# from joblib import Parallel, delayed  \n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "USERPATH = os.path.expanduser(\"~\")\n",
    "print(USERPATH)\n",
    "import six.moves.cPickle as pickle\n",
    "# import tensorflow as tf\n",
    "\n",
    "# import theano\n",
    "# theano.config.device = 'gpu'\n",
    "# theano.config.floatX = 'float32'\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras import callbacks\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "\n",
    "# server = tf.train.Server.create_local_server()\n",
    "# sess = tf.Session(server.target)\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(sess)\n",
    "\n",
    "# tb = TensorBoard(log_dir='/tmp/tensorboard', histogram_freq=1, write_graph=True)\n",
    "\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# checkpointer = ModelCheckpoint(filepath=\"weights2d.hdf5\", verbose=1, save_best_only=True)\n",
    "patchsize = [10,10,10]\n",
    "data_spacing = [1,1,1]\n",
    "patchsizeSpaced = np.array(patchsize)//np.array(data_spacing)\n",
    "patchsizeSpaced = [int(x) for x in patchsizeSpaced]\n",
    "notipsPath = USERPATH + \"/preprocessed_data/notips_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "tipsPath = USERPATH + \"/preprocessed_data/tips_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "needlesPath = USERPATH + \"/preprocessed_data/needles_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "\n",
    "casesToExclude = [64,77]\n",
    "\n",
    "\n",
    "def getTrainingPaths(tipsPath, cases=[64,77]):\n",
    "    strL = \"\"\n",
    "    for c in cases:\n",
    "        strL+=\"%03d|\"%c\n",
    "    fnames=glob.glob(tipsPath + \"/*/*.nrrd\")\n",
    "    regex=re.compile(\"^((?!%s).)*$\"%strL[:-1])\n",
    "    paths = [m.group(0) for l in fnames for m in [regex.search(l)] if m]\n",
    "    return paths\n",
    "\n",
    "def loadAllDataFromPath(path, casesToExclude):\n",
    "    # path in directorty\n",
    "    \n",
    "#     cubeTipsPath = glob.glob(path + \"/*/*.nrrd\")\n",
    "    cubeTipsPath = getTrainingPaths(path, casesToExclude)\n",
    "    # number of samples\n",
    "    N = len(cubeTipsPath)\n",
    "    print(\"content: %d\"%N)\n",
    "    \n",
    "    cubeTips = []\n",
    "    data = []\n",
    "    for path_i in cubeTipsPath:\n",
    "        cubeTips.append(nrrd.read(path_i))\n",
    "    for i in range(N):\n",
    "        c = np.array(cubeTips[i][0][:,:,:])\n",
    "        if c.shape==tuple(patchsizeSpaced):\n",
    "            data.append(np.array(c))\n",
    "    output = np.array(data, dtype='float32')\n",
    "    print('number of sample %d' %len(output))\n",
    "    return output\n",
    "\n",
    "\n",
    "print(tipsPath)\n",
    "# tips = loadAllDataFromPath(tipsPath, casesToExclude)\n",
    "# notips = loadAllDataFromPath(notipsPath, casesToExclude)[:3*len(tips)]\n",
    "\n",
    "o = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: 604\n",
      "number of sample 594\n",
      "content: 93906\n",
      "number of sample 93906\n",
      "content: 56016\n",
      "number of sample 55574\n",
      "594 2970\n",
      "target shape: (5940,)\n",
      "data shape: (5940, 10, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "tips = loadAllDataFromPath(tipsPath, casesToExclude)\n",
    "notips = loadAllDataFromPath(notipsPath, casesToExclude)[:5*len(tips)]\n",
    "needles = loadAllDataFromPath(needlesPath, casesToExclude)[:4*len(tips)]\n",
    "\n",
    "print(len(tips), len(notips))\n",
    "\n",
    "target_0 = [0 for i in range(len(notips))]\n",
    "target_1 = [1 for i in range(len(tips))]\n",
    "target_2 = [2 for i in range(len(needles))]\n",
    "y_train = np.array(target_0 + target_1 + target_2)\n",
    "print('target shape:', y_train.shape)\n",
    "X_train = np.array(list(notips)+list(tips)+ list(needles))\n",
    "\n",
    "print('data shape:', X_train.shape)\n",
    "\n",
    "f_Xtrain = open('X_data_n%d.save'%o, 'wb')\n",
    "f_ytrain = open('y_data_n%d.save'%o, 'wb')\n",
    "\n",
    "pickle.dump(X_train, f_Xtrain, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(y_train, f_ytrain, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "f_Xtrain.close()\n",
    "f_ytrain.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape and label shape\n",
      "(5940, 10, 10, 10) (5940,)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# In[6]:\n",
    "\n",
    "# Load the dataset\n",
    "f_Xdata = open('X_data_n%d.save'%o, 'rb')\n",
    "f_ydata = open('y_data_n%d.save'%o, 'rb')\n",
    "\n",
    "X_data_ = pickle.load(f_Xdata)\n",
    "X_data_ = X_data_.astype('float32')\n",
    "\n",
    "# normalize the raw data\n",
    "X_data_ -= np.mean(X_data_)\n",
    "X_data_ /= np.std(X_data_)\n",
    "\n",
    "## second method for normalization\n",
    "# X_data /= 255\n",
    "\n",
    "y_data= pickle.load(f_ydata)\n",
    "y_data_binary = to_categorical(y_data)\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_data)\n",
    "y_data = encoder.transform(y_data)\n",
    "\n",
    "print(\"Data shape and label shape\")\n",
    "print(X_data_.shape, y_data.shape)\n",
    "print(y_data_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "def shuffle_in_unison_inplace(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "# init the global var\n",
    "model = 0\n",
    "m = 133\n",
    "conv3d = False\n",
    "conv1d = False\n",
    "dimOrdering = 'tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5940, 10, 10, 10)\n",
      "Epoch 1/100\n",
      "2970/2970 [==============================] - 5s - loss: 1.0084 - acc: 0.4855     \n",
      "Epoch 2/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.9182 - acc: 0.5892     \n",
      "Epoch 3/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.7925 - acc: 0.6973     \n",
      "Epoch 4/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.6981 - acc: 0.7495     \n",
      "Epoch 5/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.6222 - acc: 0.7842     \n",
      "Epoch 6/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.5747 - acc: 0.7987     \n",
      "Epoch 7/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.5169 - acc: 0.8226     \n",
      "Epoch 8/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4746 - acc: 0.8310     \n",
      "Epoch 9/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4266 - acc: 0.8545     \n",
      "Epoch 10/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3795 - acc: 0.8724     \n",
      "Epoch 11/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3380 - acc: 0.8845     \n",
      "Epoch 12/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3166 - acc: 0.8919     \n",
      "Epoch 13/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3222 - acc: 0.8949     \n",
      "Epoch 14/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3026 - acc: 0.8970     \n",
      "Epoch 15/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2671 - acc: 0.9094     \n",
      "Epoch 16/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2504 - acc: 0.9192     \n",
      "Epoch 17/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2298 - acc: 0.9202     \n",
      "Epoch 18/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2109 - acc: 0.9340     \n",
      "Epoch 19/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1864 - acc: 0.9391     \n",
      "Epoch 20/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1698 - acc: 0.9418     \n",
      "Epoch 21/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1796 - acc: 0.9418     \n",
      "Epoch 22/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1630 - acc: 0.9468     \n",
      "Epoch 23/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1469 - acc: 0.9512     \n",
      "Epoch 24/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1402 - acc: 0.9545     \n",
      "Epoch 25/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1361 - acc: 0.9556     \n",
      "Epoch 26/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1318 - acc: 0.9559     \n",
      "Epoch 27/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1287 - acc: 0.9586     \n",
      "Epoch 28/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1124 - acc: 0.9636     \n",
      "Epoch 29/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1023 - acc: 0.9673     \n",
      "Epoch 30/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1009 - acc: 0.9653     \n",
      "Epoch 31/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1016 - acc: 0.9667     \n",
      "Epoch 32/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1144 - acc: 0.9609     \n",
      "Epoch 33/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0916 - acc: 0.9717     \n",
      "Epoch 34/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0743 - acc: 0.9774     \n",
      "Epoch 35/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0831 - acc: 0.9714     \n",
      "Epoch 36/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0758 - acc: 0.9764     \n",
      "Epoch 37/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0765 - acc: 0.9768     \n",
      "Epoch 38/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0727 - acc: 0.9795     \n",
      "Epoch 39/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0544 - acc: 0.9828     \n",
      "Epoch 40/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0499 - acc: 0.9845     \n",
      "Epoch 41/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0524 - acc: 0.9832     \n",
      "Epoch 42/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0534 - acc: 0.9835     \n",
      "Epoch 43/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0482 - acc: 0.9848     \n",
      "Epoch 44/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0671 - acc: 0.9815     \n",
      "Epoch 45/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0453 - acc: 0.9859     \n",
      "Epoch 46/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0531 - acc: 0.9835     \n",
      "Epoch 47/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0497 - acc: 0.9832     \n",
      "Epoch 48/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0492 - acc: 0.9859     \n",
      "Epoch 49/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0426 - acc: 0.9862     \n",
      "Epoch 50/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0359 - acc: 0.9889     \n",
      "Epoch 51/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0350 - acc: 0.9892     \n",
      "Epoch 52/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0338 - acc: 0.9909     \n",
      "Epoch 53/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0334 - acc: 0.9899     \n",
      "Epoch 54/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0272 - acc: 0.9933     \n",
      "Epoch 55/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0256 - acc: 0.9936     \n",
      "Epoch 56/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0283 - acc: 0.9923     \n",
      "Epoch 57/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0497 - acc: 0.9848     \n",
      "Epoch 58/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0476 - acc: 0.9835     \n",
      "Epoch 59/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0538 - acc: 0.9838     \n",
      "Epoch 60/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0365 - acc: 0.9896     \n",
      "Epoch 61/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0282 - acc: 0.9912     \n",
      "Epoch 62/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0250 - acc: 0.9919     \n",
      "Epoch 63/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0213 - acc: 0.9936     \n",
      "Epoch 64/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0225 - acc: 0.9923     \n",
      "Epoch 65/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0188 - acc: 0.9953     \n",
      "Epoch 66/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0121 - acc: 0.9966     \n",
      "Epoch 67/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0160 - acc: 0.9949     \n",
      "Epoch 68/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0210 - acc: 0.9923     \n",
      "Epoch 69/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0242 - acc: 0.9912     \n",
      "Epoch 70/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0274 - acc: 0.9936     \n",
      "Epoch 71/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0201 - acc: 0.9946     \n",
      "Epoch 72/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0247 - acc: 0.9933     \n",
      "Epoch 73/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0255 - acc: 0.9909     \n",
      "Epoch 74/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0211 - acc: 0.9946     \n",
      "Epoch 75/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0280 - acc: 0.9923     \n",
      "Epoch 76/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0172 - acc: 0.9949     \n",
      "Epoch 77/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0323 - acc: 0.9906     \n",
      "Epoch 78/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0259 - acc: 0.9916     \n",
      "Epoch 79/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0160 - acc: 0.9973     \n",
      "Epoch 80/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0205 - acc: 0.9949     \n",
      "Epoch 81/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0157 - acc: 0.9963     \n",
      "Epoch 82/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0186 - acc: 0.9949     \n",
      "Epoch 83/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0205 - acc: 0.9933     \n",
      "Epoch 84/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0144 - acc: 0.9960     \n",
      "Epoch 85/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0160 - acc: 0.9966     \n",
      "Epoch 86/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0118 - acc: 0.9976     \n",
      "Epoch 87/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0140 - acc: 0.9949     \n",
      "Epoch 88/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0112 - acc: 0.9983     \n",
      "Epoch 89/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0082 - acc: 0.9983     \n",
      "Epoch 90/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0113 - acc: 0.9970     \n",
      "Epoch 91/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0081 - acc: 0.9976     \n",
      "Epoch 92/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0100 - acc: 0.9973     \n",
      "Epoch 93/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0129 - acc: 0.9960     \n",
      "Epoch 94/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0195 - acc: 0.9939     \n",
      "Epoch 95/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0232 - acc: 0.9926     \n",
      "Epoch 96/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0167 - acc: 0.9943     \n",
      "Epoch 97/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0153 - acc: 0.9953     \n",
      "Epoch 98/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0236 - acc: 0.9946     \n",
      "Epoch 99/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0228 - acc: 0.9956     \n",
      "Epoch 100/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0141 - acc: 0.9953     \n",
      "2560/2970 [========================>.....] - ETA: 0sEpoch 1/100\n",
      "2970/2970 [==============================] - 0s - loss: 1.0255 - acc: 0.4700     \n",
      "Epoch 2/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.9306 - acc: 0.5657     \n",
      "Epoch 3/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.8727 - acc: 0.6428     \n",
      "Epoch 4/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.7529 - acc: 0.7138     \n",
      "Epoch 5/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.6568 - acc: 0.7640     \n",
      "Epoch 6/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.5890 - acc: 0.7933     \n",
      "Epoch 7/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.5088 - acc: 0.8121     \n",
      "Epoch 8/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4763 - acc: 0.8333     \n",
      "Epoch 9/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4353 - acc: 0.8350     \n",
      "Epoch 10/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3924 - acc: 0.8552     \n",
      "Epoch 11/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3709 - acc: 0.8687     \n",
      "Epoch 12/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3235 - acc: 0.8781     \n",
      "Epoch 13/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3081 - acc: 0.8923     \n",
      "Epoch 14/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2700 - acc: 0.9074     \n",
      "Epoch 15/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2563 - acc: 0.9128     \n",
      "Epoch 16/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2428 - acc: 0.9168     \n",
      "Epoch 17/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1975 - acc: 0.9316     \n",
      "Epoch 18/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1723 - acc: 0.9428     \n",
      "Epoch 19/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1635 - acc: 0.9461     \n",
      "Epoch 20/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1638 - acc: 0.9471     \n",
      "Epoch 21/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1607 - acc: 0.9461     \n",
      "Epoch 22/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1253 - acc: 0.9579     \n",
      "Epoch 23/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1266 - acc: 0.9569     \n",
      "Epoch 24/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1109 - acc: 0.9616     \n",
      "Epoch 25/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1134 - acc: 0.9596     \n",
      "Epoch 26/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1220 - acc: 0.9609     \n",
      "Epoch 27/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1059 - acc: 0.9687     \n",
      "Epoch 28/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1030 - acc: 0.9616     \n",
      "Epoch 29/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0945 - acc: 0.9690     \n",
      "Epoch 30/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0832 - acc: 0.9747     \n",
      "Epoch 31/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0687 - acc: 0.9747     \n",
      "Epoch 32/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0612 - acc: 0.9781     \n",
      "Epoch 33/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0715 - acc: 0.9781     \n",
      "Epoch 34/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0571 - acc: 0.9811     \n",
      "Epoch 35/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0455 - acc: 0.9835     \n",
      "Epoch 36/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0424 - acc: 0.9862     \n",
      "Epoch 37/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0375 - acc: 0.9886     \n",
      "Epoch 38/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0370 - acc: 0.9886     \n",
      "Epoch 39/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0418 - acc: 0.9852     \n",
      "Epoch 40/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0422 - acc: 0.9862     \n",
      "Epoch 41/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0370 - acc: 0.9875     \n",
      "Epoch 42/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0326 - acc: 0.9879     \n",
      "Epoch 43/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0257 - acc: 0.9939     \n",
      "Epoch 44/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0304 - acc: 0.9899     \n",
      "Epoch 45/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0221 - acc: 0.9939     \n",
      "Epoch 46/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0269 - acc: 0.9919     \n",
      "Epoch 47/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0260 - acc: 0.9912     \n",
      "Epoch 48/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0187 - acc: 0.9963     \n",
      "Epoch 49/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0332 - acc: 0.9912     \n",
      "Epoch 50/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0662 - acc: 0.9859     \n",
      "Epoch 51/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0803 - acc: 0.9758     \n",
      "Epoch 52/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0656 - acc: 0.9801     \n",
      "Epoch 53/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0464 - acc: 0.9859     \n",
      "Epoch 54/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0472 - acc: 0.9852     \n",
      "Epoch 55/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0376 - acc: 0.9882     \n",
      "Epoch 56/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0327 - acc: 0.9879     \n",
      "Epoch 57/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0262 - acc: 0.9929     \n",
      "Epoch 58/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0186 - acc: 0.9939     \n",
      "Epoch 59/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0175 - acc: 0.9956     \n",
      "Epoch 60/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0216 - acc: 0.9943     \n",
      "Epoch 61/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0166 - acc: 0.9960     \n",
      "Epoch 62/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0174 - acc: 0.9939     \n",
      "Epoch 63/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0138 - acc: 0.9963     \n",
      "Epoch 64/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0116 - acc: 0.9976     \n",
      "Epoch 65/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0174 - acc: 0.9926     \n",
      "Epoch 66/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0165 - acc: 0.9956     \n",
      "Epoch 67/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0318 - acc: 0.9912     \n",
      "Epoch 68/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0115 - acc: 0.9973     \n",
      "Epoch 69/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0135 - acc: 0.9963     \n",
      "Epoch 70/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0095 - acc: 0.9963     \n",
      "Epoch 71/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0114 - acc: 0.9973     \n",
      "Epoch 72/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0071 - acc: 0.9973     \n",
      "Epoch 73/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0080 - acc: 0.9970     \n",
      "Epoch 74/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0046 - acc: 0.9990     \n",
      "Epoch 75/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0066 - acc: 0.9980     \n",
      "Epoch 76/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0091 - acc: 0.9960     \n",
      "Epoch 77/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0098 - acc: 0.9980     \n",
      "Epoch 78/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0092 - acc: 0.9973     \n",
      "Epoch 79/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0066 - acc: 0.9973     \n",
      "Epoch 80/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0075 - acc: 0.9983     \n",
      "Epoch 81/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0150 - acc: 0.9949     \n",
      "Epoch 82/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0112 - acc: 0.9976     \n",
      "Epoch 83/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0075 - acc: 0.9980     \n",
      "Epoch 84/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0095 - acc: 0.9973     \n",
      "Epoch 85/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0104 - acc: 0.9966     \n",
      "Epoch 86/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0100 - acc: 0.9976     \n",
      "Epoch 87/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0079 - acc: 0.9973     \n",
      "Epoch 88/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0235 - acc: 0.9946     \n",
      "Epoch 89/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0193 - acc: 0.9926     \n",
      "Epoch 90/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0185 - acc: 0.9936     \n",
      "Epoch 91/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0104 - acc: 0.9983     \n",
      "Epoch 92/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0110 - acc: 0.9976     \n",
      "Epoch 93/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0107 - acc: 0.9976     \n",
      "Epoch 94/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0101 - acc: 0.9976     \n",
      "Epoch 95/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0058 - acc: 0.9990     \n",
      "Epoch 96/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0057 - acc: 0.9990     \n",
      "Epoch 97/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0065 - acc: 0.9983     \n",
      "Epoch 98/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0030 - acc: 1.0000     \n",
      "Epoch 99/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0121 - acc: 0.9966     \n",
      "Epoch 100/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0062 - acc: 0.9976     \n",
      "2560/2970 [========================>.....] - ETA: 0sStandardized: 93.45% (0.29%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2489"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline():\n",
    "\n",
    "    nb_classes = 3\n",
    "\n",
    "    # create model\n",
    "    global model\n",
    "        \n",
    "    if m ==132:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=patchsizeSpaced, activation='relu', name='conv1_0'))\n",
    "        model.add(ZeroPadding2D((2, 2)))\n",
    "        model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "        model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "    if m ==133:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=patchsizeSpaced, activation='relu', name='conv1_0'))\n",
    "#         model.add(ZeroPadding2D((2, 2)))\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_1'))\n",
    "        model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv2_0'))\n",
    "#         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv2_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv2_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.2))\n",
    "        \n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv3_0'))\n",
    "#         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv3_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv3_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# np.random.seed(seed)\n",
    "estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, nb_epoch=100,\n",
    "                                          batch_size=512, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(y=y_data, n_folds=2, shuffle=True)#, random_state=seed)\n",
    "if not conv1d and dimOrdering == 'th':\n",
    "    X_data = np.swapaxes(X_data_,1,3)\n",
    "    X_data = np.swapaxes(X_data,2,3)\n",
    "    print(X_data.shape)\n",
    "elif conv1d:\n",
    "    print(X_data_.shape)\n",
    "    X_data = X_data_.reshape((X_data_.shape[0], X_data_.shape[1]* X_data_.shape[2], X_data_.shape[3]))\n",
    "    print(X_data.shape)\n",
    "else:\n",
    "    X_data = X_data_\n",
    "\n",
    "if conv3d:\n",
    "    X_data =  np.expand_dims(X_data, 1)\n",
    "    \n",
    "print(X_data.shape)\n",
    "results = cross_val_score(pipeline,X_data, y_data_binary, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "json_string = model.to_json()\n",
    "model.save_weights('my_model_weights_2d_%d.h5'%m, overwrite=True)\n",
    "open('my_model_architecture%d.json'%m, 'w').write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "(60, 50, 90)\n",
      "[10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# we load a test case and the model\n",
    "\n",
    "# model = model_from_json(open('my_model_architecture%d.json'%m).read())\n",
    "# model.load_weights('my_model_weights_2d_%d.h5'%m)\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "print(data_spacing)\n",
    "nrrdData = nrrd.read(USERPATH + '/preprocessed_data/LabelMaps_%.2f-%.2f-%.2f/064/case.nrrd'%(tuple(data_spacing)))\n",
    "im = nrrdData[0]\n",
    "# im = im[100//data_spacing[0]:160//data_spacing[0],80//data_spacing[1]:130//data_spacing[1],70//data_spacing[2]:160//data_spacing[2]]\n",
    "im = im[100:160,80:130,70:160]\n",
    "s = im.shape\n",
    "print(s)\n",
    "print(patchsizeSpaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pyprind\n",
    "# import sys\n",
    "# def findtips(N):\n",
    "#     '''\n",
    "#     Find the tip in the image by computing testing patches at every voxel position\n",
    "#     TODO: make this method more efficient\n",
    "#     '''\n",
    "#     p0, p1, p2 = patchsize\n",
    "#     xmiddle = s[0]//2\n",
    "#     ymiddle = s[1]//2\n",
    "#     zmiddle = s[2]//2\n",
    "    \n",
    "#     x0= xmiddle - xmiddle//N\n",
    "#     y0= ymiddle - ymiddle//N\n",
    "#     z0= zmiddle - zmiddle//N\n",
    "    \n",
    "#     xe= xmiddle + xmiddle//N\n",
    "#     ye= ymiddle + ymiddle//N\n",
    "#     ze= zmiddle + zmiddle//N\n",
    "    \n",
    "#     tips = []\n",
    "#     bar = pyprind.ProgBar(xmiddle//N*2, title='Find_tip', stream=sys.stdout)\n",
    "#     for xi in range(x0, xe-p0):\n",
    "#         for yi in range(y0, ye-p1):\n",
    "#             vols = [im[xi:xi+p0,yi:yi+p1,zi:zi+p2] for zi in range(z0,ze-p2)]\n",
    "#             # we normalize the data (centered on mean 0 and rescaled in function of the STD)\n",
    "#             volnorm = [ x-np.mean(x) for x in vols]\n",
    "#             volnorm2 = [x/np.std(x) for x in volnorm]\n",
    "#             cube = np.array(volnorm2)\n",
    "#             cube = np.swapaxes(cube, 1,3)\n",
    "# #             cube = np.swapaxes(cube, 2,3)\n",
    "#             if conv3d:\n",
    "#                 cube = np.expand_dims(cube,1)\n",
    "#             res = model.predict_proba(cube, batch_size=ze-p2-z0, verbose=False)\n",
    "#             indices = np.where(res[:,0]==1)\n",
    "#             # we add the coordinates of the center voxel of the patches that tested positive\n",
    "#             for z in indices[0]:\n",
    "#                 tips.append([xi+p0/2,yi+p1/2,z0+p2/2+z])\n",
    "#         bar.update()\n",
    "#     return tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import sys\n",
    "def gettips(N):\n",
    "    '''\n",
    "    Find the tip in the image by computing testing patches at every voxel position\n",
    "    TODO: make this method more efficient\n",
    "    '''\n",
    "    p0, p1, p2 = patchsizeSpaced\n",
    "    x0, y0, z0 = 0,0,0\n",
    "    xe, ye, ze = s\n",
    "    \n",
    "    tips = []\n",
    "    bar = pyprind.ProgBar(s[0], title='Find_tip', stream=sys.stdout)\n",
    "    res = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            vols = [im[xi:xi+p0,yi:yi+p1,zi:zi+p2] for zi in range(z0,ze-p2)]\n",
    "            # we normalize the data (centered on mean 0 and rescaled in function of the STD)\n",
    "            volnorm = vols - np.mean(vols)\n",
    "            volnorm2 = volnorm/np.std(volnorm)\n",
    "            cube = np.array(volnorm2)\n",
    "            if not conv1d and dimOrdering == 'th':\n",
    "                cube = np.swapaxes(cube, 1,3)\n",
    "            if conv3d:\n",
    "                cube = np.expand_dims(cube,1)\n",
    "            if conv1d:\n",
    "                cube = cube.reshape(cube.shape[0], cube.shape[1]*cube.shape[2],cube.shape[3])\n",
    "                \n",
    "            res.append(model.predict_proba(cube, batch_size=ze-p2-z0, verbose=False))\n",
    "        bar.update()\n",
    "    return np.array(res)\n",
    "\n",
    "def findtips(res, prob):\n",
    "    N=1\n",
    "    p0, p1, p2 = patchsizeSpaced\n",
    "    \n",
    "    x0, y0, z0 = 0,0,0\n",
    "    xe, ye, ze = s\n",
    "    \n",
    "    i = -1\n",
    "    tips = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            i+=1\n",
    "            indices = np.where(res[i][:,0]>=prob)\n",
    "            # we add the coordinates of the center voxel of the patches that tested positive\n",
    "            for z in indices[0]:\n",
    "                tips.append([xi+p0/2, yi+p1/2, z0+p2/2+z])\n",
    "    return tips\n",
    "\n",
    "def findtips3classes(res, prob, cat):\n",
    "    N=1\n",
    "    res = res[:,:,cat]\n",
    "    p0, p1, p2 = patchsizeSpaced\n",
    "    \n",
    "    x0, y0, z0 = 0,0,0\n",
    "    xe, ye, ze = s\n",
    "    \n",
    "    i = -1\n",
    "    tips = []\n",
    "    for xi in range(x0, xe-p0-1):\n",
    "        for yi in range(y0, ye-p1-1):\n",
    "            i+=1\n",
    "            indices = np.where(res[i][:]>=prob)\n",
    "            # we add the coordinates of the center voxel of the patches that tested positive\n",
    "            for z in indices[0]:\n",
    "                tips.append([xi+p0/2, yi+p1/2, z0+p2/2+z])\n",
    "\n",
    "    return tips\n",
    "\n",
    "def findtips3classes2(res, prob):\n",
    "    N=1\n",
    "    res = (res[:,:,2] + res[:,:,1])/2\n",
    "    p0, p1, p2 = patchsizeSpaced\n",
    "\n",
    "    x0, y0, z0 = 0,0,0\n",
    "    xe, ye, ze = s\n",
    "    \n",
    "    i = -1\n",
    "    tips = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            i+=1\n",
    "            indices = np.where(res[i][:]>=prob)\n",
    "            # we add the coordinates of the center voxel of the patches that tested positive\n",
    "            for z in indices[0]:\n",
    "                tips.append([xi+p0/2, yi+p1/2, z0+p2/2+z])\n",
    "    return tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# find the tips for patches with size p\n",
    "print(patchsizeSpaced)\n",
    "pred=gettips(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 80, 3)\n",
      "2000\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.set_printoptions(precision=2)\n",
    "pred [ pred < 0.1] = 0\n",
    "print(pred.shape)\n",
    "print(len(pred[:,:,1]))\n",
    "print(pred[:,:,1])\n",
    "# res = findtips(pred, 1)\n",
    "res = findtips3classes(pred, 1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25.0, 7.0, 56.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of a labelmap from the voxel that tested positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(im.shape)\n",
    "for coord in res:\n",
    "    mask[int(coord[0]),int(coord[1]),int(coord[2])]=1.0\n",
    "nrrd.write('mask%d.nrrd'%m, mask)\n",
    "nrrd.write('im%d.nrrd'%m, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['seed']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1af6fde898>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzIAAAFRCAYAAACvypjwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1af70b6160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "# We display one axial slice\n",
    "Z = 18\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow((np.clip(mask[:,:,Z]*255+im[:,:,Z]/2,a_min=0,a_max=200)).transpose(),  cmap='gray', interpolation='nearest')\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.imshow(im[:,:,Z].transpose(), cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     if m ==7:\n",
    "#         model = Sequential()\n",
    "\n",
    "#         model.add(Convolution2D(10, 10, 2, border_mode='same',\n",
    "#                                 input_shape=(10,10,10)))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(10, 3, 3))\n",
    "#         model.add(Activation('relu'))\n",
    "#         # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#         model.add(Dropout(0.1))\n",
    "\n",
    "#         model.add(Convolution2D(40, 5, 3, border_mode='same' ))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(40, 5, 3, border_mode='same'))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(40, 5, 3))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#         model.add(Dropout(0.1))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "\n",
    "#     if m == 11:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same',\n",
    "#                                 batch_input_shape=(10, 10, 10)))\n",
    "#         # model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, 10, 10)))\n",
    "#         model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(Flatten(input_shape=(512,3,3)))\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "\n",
    "#     if m ==13:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=(10,10,10), activation='relu', name='conv1_0'))\n",
    "# #         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(200, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(100, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "#     if m ==132:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=(10,10,10), activation='relu', name='conv1_0'))\n",
    "# #         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(200, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(100, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "#     if m ==132:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=(10,10,10), activation='relu', name='conv1_0'))\n",
    "# #         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(200, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(100, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "#     if m ==14:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(20, 10, 10, border_mode='same', input_shape=(10,10,20), activation='relu', name='conv1_0'))\n",
    "#         model.add(Convolution2D(20, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "#         model.add(Convolution2D(20, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "        \n",
    "#         model.add(Convolution2D(20, 10, 10, border_mode='same', input_shape=(10,10,20), activation='relu', name='conv2_0'))\n",
    "#         model.add(Convolution2D(20, 5, 5, border_mode='same', activation='relu', name='conv2_1'))\n",
    "#         model.add(Convolution2D(20, 10, 10, border_mode='same', activation='relu', name='conv2_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(200, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(100, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "        \n",
    "#     if m ==15:\n",
    "#         model = Sequential()\n",
    "\n",
    "#         model.add(Convolution2D(100,2,2, border_mode='same', \n",
    "#                                 input_shape=(20,10,10)))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(50,2,2))\n",
    "# #         model.add(Activation('relu'))\n",
    "# #         model.add(Convolution2D(60,4,4))\n",
    "# #         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#         model.add(Dropout(0.25))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "    \n",
    "#     if m == 16:\n",
    "#         model = Sequential()\n",
    "\n",
    "#         model.add(Convolution3D(20,9,9,18, border_mode='same',\n",
    "#                                 input_shape=(1,10,10,20)))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution3D(20,9,9,19))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# #         model.add(Dropout(0.25))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "        \n",
    "#     if m ==18:\n",
    "#         model = Sequential()\n",
    "\n",
    "#         model.add(ZeroPadding2D((1,1),input_shape=(20,10,10)))\n",
    "#         model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(4096, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(4096, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        \n",
    "#     if m ==20:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution1D(100,10, activation='relu', input_shape=(100,10)))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Convolution1D(100,10, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Convolution1D(100,10, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Convolution1D(100,10, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(MaxPooling1D((5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
