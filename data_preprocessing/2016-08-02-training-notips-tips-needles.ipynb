{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/preprocessed_data/tips_10-10-10_1.00-1.00-1.00/\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from __future__ import division\n",
    "import joblib\n",
    "import glob\n",
    "import os, re\n",
    "import numpy as np\n",
    "import nrrd\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics, decomposition\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "from joblib import Parallel, delayed  \n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "USERPATH = os.path.expanduser(\"~\")\n",
    "print(USERPATH)\n",
    "import six.moves.cPickle as pickle\n",
    "# import tensorflow as tf\n",
    "\n",
    "# import theano\n",
    "# theano.config.device = 'gpu'\n",
    "# theano.config.floatX = 'float32'\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras import callbacks\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "\n",
    "# server = tf.train.Server.create_local_server()\n",
    "# sess = tf.Session(server.target)\n",
    "\n",
    "# from keras import backend as K\n",
    "# K.set_session(sess)\n",
    "\n",
    "# tb = TensorBoard(log_dir='/tmp/tensorboard', histogram_freq=1, write_graph=True)\n",
    "\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# checkpointer = ModelCheckpoint(filepath=\"weights2d.hdf5\", verbose=1, save_best_only=True)\n",
    "patchsize = [10,10,10]\n",
    "data_spacing = [1,1,1]\n",
    "patchsizeSpaced = np.array(patchsize)//np.array(data_spacing)\n",
    "patchsizeSpaced = [int(x) for x in patchsizeSpaced]\n",
    "notipsPath = USERPATH + \"/preprocessed_data/notips_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "tipsPath = USERPATH + \"/preprocessed_data/tips_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "needlesPath = USERPATH + \"/preprocessed_data/needles_%d-%d-%d_%.2f-%.2f-%.2f/\" %(tuple(patchsize)+tuple(data_spacing))\n",
    "\n",
    "casesToExclude = [64,77]\n",
    "\n",
    "\n",
    "def getTrainingPaths(tipsPath, cases=[64,77]):\n",
    "    strL = \"\"\n",
    "    for c in cases:\n",
    "        strL+=\"%03d|\"%c\n",
    "    fnames=glob.glob(tipsPath + \"/*/*.nrrd\")\n",
    "    regex=re.compile(\"^((?!%s).)*$\"%strL[:-1])\n",
    "    paths = [m.group(0) for l in fnames for m in [regex.search(l)] if m]\n",
    "    return paths\n",
    "\n",
    "def loadAllDataFromPath(path, casesToExclude):\n",
    "    # path in directorty\n",
    "    \n",
    "#     cubeTipsPath = glob.glob(path + \"/*/*.nrrd\")\n",
    "    cubeTipsPath = getTrainingPaths(path, casesToExclude)\n",
    "    # number of samples\n",
    "    N = len(cubeTipsPath)\n",
    "    print(\"content: %d\"%N)\n",
    "    \n",
    "    cubeTips = []\n",
    "    data = []\n",
    "    for path_i in cubeTipsPath:\n",
    "        cubeTips.append(nrrd.read(path_i))\n",
    "    for i in range(N):\n",
    "        c = np.array(cubeTips[i][0][:,:,:])\n",
    "        if c.shape==tuple(patchsizeSpaced):\n",
    "            data.append(np.array(c))\n",
    "    output = np.array(data, dtype='float32')\n",
    "    print('number of sample %d' %len(output))\n",
    "    return output\n",
    "\n",
    "\n",
    "print(tipsPath)\n",
    "# tips = loadAllDataFromPath(tipsPath, casesToExclude)\n",
    "# notips = loadAllDataFromPath(notipsPath, casesToExclude)[:3*len(tips)]\n",
    "\n",
    "o = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: 604\n",
      "number of sample 594\n",
      "content: 93906\n",
      "number of sample 93906\n",
      "content: 56016\n",
      "number of sample 55574\n",
      "594 2970\n",
      "target shape: (5940,)\n",
      "data shape: (5940, 10, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "tips = loadAllDataFromPath(tipsPath, casesToExclude)\n",
    "notips = loadAllDataFromPath(notipsPath, casesToExclude)[:5*len(tips)]\n",
    "needles = loadAllDataFromPath(needlesPath, casesToExclude)[:4*len(tips)]\n",
    "\n",
    "print(len(tips), len(notips))\n",
    "\n",
    "target_0 = [0 for i in range(len(notips))]\n",
    "target_1 = [1 for i in range(len(tips))]\n",
    "target_2 = [2 for i in range(len(needles))]\n",
    "y_train = np.array(target_0 + target_1 + target_2)\n",
    "print('target shape:', y_train.shape)\n",
    "X_train = np.array(list(notips)+list(tips)+ list(needles))\n",
    "\n",
    "print('data shape:', X_train.shape)\n",
    "\n",
    "f_Xtrain = open('X_data_n%d.save'%o, 'wb')\n",
    "f_ytrain = open('y_data_n%d.save'%o, 'wb')\n",
    "\n",
    "pickle.dump(X_train, f_Xtrain, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(y_train, f_ytrain, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "f_Xtrain.close()\n",
    "f_ytrain.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape and label shape\n",
      "(5940, 10, 10, 10) (5940,)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# In[6]:\n",
    "\n",
    "# Load the dataset\n",
    "f_Xdata = open('X_data_n%d.save'%o, 'rb')\n",
    "f_ydata = open('y_data_n%d.save'%o, 'rb')\n",
    "\n",
    "X_data_ = pickle.load(f_Xdata)\n",
    "X_data_ = X_data_.astype('float32')\n",
    "\n",
    "# normalize the raw data\n",
    "X_data_ -= np.mean(X_data_)\n",
    "X_data_ /= np.std(X_data_)\n",
    "\n",
    "## second method for normalization\n",
    "# X_data /= 255\n",
    "\n",
    "y_data= pickle.load(f_ydata)\n",
    "y_data_binary = to_categorical(y_data)\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_data)\n",
    "y_data = encoder.transform(y_data)\n",
    "\n",
    "print(\"Data shape and label shape\")\n",
    "print(X_data_.shape, y_data.shape)\n",
    "print(y_data_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "def shuffle_in_unison_inplace(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "# init the global var\n",
    "model = 0\n",
    "m = 133\n",
    "conv3d = False\n",
    "conv1d = False\n",
    "dimOrdering = 'tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5940, 10, 10, 10)\n",
      "Epoch 1/100\n",
      "2970/2970 [==============================] - 1s - loss: 0.9849 - acc: 0.4744     \n",
      "Epoch 2/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.9139 - acc: 0.5643     \n",
      "Epoch 3/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.8332 - acc: 0.6488     \n",
      "Epoch 4/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.7233 - acc: 0.7340     \n",
      "Epoch 5/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.6493 - acc: 0.7663     \n",
      "Epoch 6/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.5709 - acc: 0.7990     \n",
      "Epoch 7/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.5444 - acc: 0.8061     \n",
      "Epoch 8/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4886 - acc: 0.8306     \n",
      "Epoch 9/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4404 - acc: 0.8502     \n",
      "Epoch 10/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4359 - acc: 0.8549     \n",
      "Epoch 11/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4035 - acc: 0.8623     \n",
      "Epoch 12/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4148 - acc: 0.8660     \n",
      "Epoch 13/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3939 - acc: 0.8680     \n",
      "Epoch 14/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3505 - acc: 0.8889     \n",
      "Epoch 15/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3372 - acc: 0.8865     \n",
      "Epoch 16/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3272 - acc: 0.8956     \n",
      "Epoch 17/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3090 - acc: 0.9013     \n",
      "Epoch 18/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2781 - acc: 0.9098     \n",
      "Epoch 19/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2582 - acc: 0.9212     \n",
      "Epoch 20/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2528 - acc: 0.9232     \n",
      "Epoch 21/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2200 - acc: 0.9273     \n",
      "Epoch 22/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2116 - acc: 0.9313     \n",
      "Epoch 23/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2087 - acc: 0.9330     \n",
      "Epoch 24/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1937 - acc: 0.9391     \n",
      "Epoch 25/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1909 - acc: 0.9377     \n",
      "Epoch 26/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1699 - acc: 0.9441     \n",
      "Epoch 27/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1748 - acc: 0.9488     \n",
      "Epoch 28/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1573 - acc: 0.9498     \n",
      "Epoch 29/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1527 - acc: 0.9542     \n",
      "Epoch 30/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1572 - acc: 0.9488     \n",
      "Epoch 31/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1480 - acc: 0.9562     \n",
      "Epoch 32/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1463 - acc: 0.9545     \n",
      "Epoch 33/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1609 - acc: 0.9525     \n",
      "Epoch 34/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1378 - acc: 0.9545     \n",
      "Epoch 35/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1271 - acc: 0.9646     \n",
      "Epoch 36/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1279 - acc: 0.9636     \n",
      "Epoch 37/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1143 - acc: 0.9643     \n",
      "Epoch 38/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0996 - acc: 0.9717     \n",
      "Epoch 39/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0879 - acc: 0.9680     \n",
      "Epoch 40/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0870 - acc: 0.9747     \n",
      "Epoch 41/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0765 - acc: 0.9798     \n",
      "Epoch 42/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0828 - acc: 0.9761     \n",
      "Epoch 43/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0774 - acc: 0.9781     \n",
      "Epoch 44/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0737 - acc: 0.9788     \n",
      "Epoch 45/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0783 - acc: 0.9771     \n",
      "Epoch 46/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0755 - acc: 0.9785     \n",
      "Epoch 47/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0715 - acc: 0.9808     \n",
      "Epoch 48/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0672 - acc: 0.9801     \n",
      "Epoch 49/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0770 - acc: 0.9778     \n",
      "Epoch 50/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0741 - acc: 0.9788     \n",
      "Epoch 51/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0650 - acc: 0.9815     \n",
      "Epoch 52/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0635 - acc: 0.9818     \n",
      "Epoch 53/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0755 - acc: 0.9774     \n",
      "Epoch 54/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0562 - acc: 0.9832     \n",
      "Epoch 55/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0529 - acc: 0.9872     \n",
      "Epoch 56/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0430 - acc: 0.9899     \n",
      "Epoch 57/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0438 - acc: 0.9882     \n",
      "Epoch 58/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0440 - acc: 0.9899     \n",
      "Epoch 59/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0508 - acc: 0.9872     \n",
      "Epoch 60/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0425 - acc: 0.9886     \n",
      "Epoch 61/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0438 - acc: 0.9879     \n",
      "Epoch 62/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0497 - acc: 0.9859     \n",
      "Epoch 63/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0452 - acc: 0.9882     \n",
      "Epoch 64/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0361 - acc: 0.9886     \n",
      "Epoch 65/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0418 - acc: 0.9886     \n",
      "Epoch 66/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0421 - acc: 0.9862     \n",
      "Epoch 67/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0480 - acc: 0.9872     \n",
      "Epoch 68/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0607 - acc: 0.9852     \n",
      "Epoch 69/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0567 - acc: 0.9859     \n",
      "Epoch 70/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0522 - acc: 0.9882     \n",
      "Epoch 71/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0499 - acc: 0.9892     \n",
      "Epoch 72/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0423 - acc: 0.9896     \n",
      "Epoch 73/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0424 - acc: 0.9859     \n",
      "Epoch 74/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0446 - acc: 0.9882     \n",
      "Epoch 75/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0441 - acc: 0.9872     \n",
      "Epoch 76/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0623 - acc: 0.9842     \n",
      "Epoch 77/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0608 - acc: 0.9835     \n",
      "Epoch 78/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0557 - acc: 0.9832     \n",
      "Epoch 79/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0539 - acc: 0.9852     \n",
      "Epoch 80/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0648 - acc: 0.9815     \n",
      "Epoch 81/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0518 - acc: 0.9872     \n",
      "Epoch 82/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0474 - acc: 0.9872     \n",
      "Epoch 83/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0430 - acc: 0.9875     \n",
      "Epoch 84/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0425 - acc: 0.9869     \n",
      "Epoch 85/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0365 - acc: 0.9896     \n",
      "Epoch 86/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0416 - acc: 0.9886     \n",
      "Epoch 87/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0356 - acc: 0.9902     \n",
      "Epoch 88/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0367 - acc: 0.9896     \n",
      "Epoch 89/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0393 - acc: 0.9886     \n",
      "Epoch 90/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0401 - acc: 0.9889     \n",
      "Epoch 91/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0436 - acc: 0.9875     \n",
      "Epoch 92/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0428 - acc: 0.9879     \n",
      "Epoch 93/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0333 - acc: 0.9926     \n",
      "Epoch 94/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0615 - acc: 0.9852     \n",
      "Epoch 95/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0775 - acc: 0.9805     \n",
      "Epoch 96/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0533 - acc: 0.9848     \n",
      "Epoch 97/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0418 - acc: 0.9889     \n",
      "Epoch 98/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0459 - acc: 0.9906     \n",
      "Epoch 99/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0429 - acc: 0.9879     \n",
      "Epoch 100/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0448 - acc: 0.9896     \n",
      "2970/2970 [==============================] - 0s     \n",
      "Epoch 1/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.9873 - acc: 0.4832     \n",
      "Epoch 2/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.9152 - acc: 0.5232     \n",
      "Epoch 3/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.8779 - acc: 0.5912     \n",
      "Epoch 4/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.8171 - acc: 0.6293     \n",
      "Epoch 5/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.7539 - acc: 0.6946     \n",
      "Epoch 6/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.6908 - acc: 0.7391     \n",
      "Epoch 7/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.6427 - acc: 0.7556     \n",
      "Epoch 8/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.5837 - acc: 0.7872     \n",
      "Epoch 9/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.5441 - acc: 0.8054     \n",
      "Epoch 10/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4935 - acc: 0.8249     \n",
      "Epoch 11/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4545 - acc: 0.8465     \n",
      "Epoch 12/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.4120 - acc: 0.8539     \n",
      "Epoch 13/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3848 - acc: 0.8690     \n",
      "Epoch 14/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3596 - acc: 0.8774     \n",
      "Epoch 15/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3401 - acc: 0.8832     \n",
      "Epoch 16/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.3135 - acc: 0.8926     \n",
      "Epoch 17/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2915 - acc: 0.9030     \n",
      "Epoch 18/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2655 - acc: 0.9138     \n",
      "Epoch 19/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2692 - acc: 0.9104     \n",
      "Epoch 20/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2609 - acc: 0.9168     \n",
      "Epoch 21/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2354 - acc: 0.9215     \n",
      "Epoch 22/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2268 - acc: 0.9293     \n",
      "Epoch 23/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2108 - acc: 0.9367     \n",
      "Epoch 24/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2171 - acc: 0.9283     \n",
      "Epoch 25/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2070 - acc: 0.9350     \n",
      "Epoch 26/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2221 - acc: 0.9290     \n",
      "Epoch 27/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2031 - acc: 0.9394     \n",
      "Epoch 28/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1945 - acc: 0.9438     \n",
      "Epoch 29/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1783 - acc: 0.9418     \n",
      "Epoch 30/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1563 - acc: 0.9498     \n",
      "Epoch 31/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1670 - acc: 0.9434     \n",
      "Epoch 32/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.2048 - acc: 0.9347     \n",
      "Epoch 33/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1790 - acc: 0.9431     \n",
      "Epoch 34/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1492 - acc: 0.9542     \n",
      "Epoch 35/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1365 - acc: 0.9589     \n",
      "Epoch 36/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1312 - acc: 0.9589     \n",
      "Epoch 37/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1377 - acc: 0.9562     \n",
      "Epoch 38/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1315 - acc: 0.9620     \n",
      "Epoch 39/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1298 - acc: 0.9599     \n",
      "Epoch 40/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1193 - acc: 0.9626     \n",
      "Epoch 41/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1194 - acc: 0.9616     \n",
      "Epoch 42/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1210 - acc: 0.9586     \n",
      "Epoch 43/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1066 - acc: 0.9670     \n",
      "Epoch 44/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1025 - acc: 0.9697     \n",
      "Epoch 45/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.1183 - acc: 0.9596     \n",
      "Epoch 46/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0962 - acc: 0.9707     \n",
      "Epoch 47/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0852 - acc: 0.9758     \n",
      "Epoch 48/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0797 - acc: 0.9774     \n",
      "Epoch 49/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0772 - acc: 0.9764     \n",
      "Epoch 50/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0860 - acc: 0.9731     \n",
      "Epoch 51/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0831 - acc: 0.9747     \n",
      "Epoch 52/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0785 - acc: 0.9771     \n",
      "Epoch 53/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0767 - acc: 0.9778     \n",
      "Epoch 54/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0703 - acc: 0.9808     \n",
      "Epoch 55/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0676 - acc: 0.9815     \n",
      "Epoch 56/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0597 - acc: 0.9815     \n",
      "Epoch 57/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0594 - acc: 0.9845     \n",
      "Epoch 58/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0678 - acc: 0.9795     \n",
      "Epoch 59/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0644 - acc: 0.9832     \n",
      "Epoch 60/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0538 - acc: 0.9845     \n",
      "Epoch 61/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0475 - acc: 0.9865     \n",
      "Epoch 62/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0470 - acc: 0.9886     \n",
      "Epoch 63/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0509 - acc: 0.9852     \n",
      "Epoch 64/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0660 - acc: 0.9781     \n",
      "Epoch 65/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0794 - acc: 0.9785     \n",
      "Epoch 66/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0694 - acc: 0.9795     \n",
      "Epoch 67/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0632 - acc: 0.9832     \n",
      "Epoch 68/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0586 - acc: 0.9825     \n",
      "Epoch 69/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0567 - acc: 0.9869     \n",
      "Epoch 70/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0492 - acc: 0.9862     \n",
      "Epoch 71/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0541 - acc: 0.9838     \n",
      "Epoch 72/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0564 - acc: 0.9855     \n",
      "Epoch 73/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0594 - acc: 0.9808     \n",
      "Epoch 74/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0582 - acc: 0.9828     \n",
      "Epoch 75/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0507 - acc: 0.9852     \n",
      "Epoch 76/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0557 - acc: 0.9842     \n",
      "Epoch 77/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0543 - acc: 0.9848     \n",
      "Epoch 78/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0490 - acc: 0.9859     \n",
      "Epoch 79/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0527 - acc: 0.9838     \n",
      "Epoch 80/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0443 - acc: 0.9875     \n",
      "Epoch 81/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0482 - acc: 0.9862     \n",
      "Epoch 82/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0458 - acc: 0.9862     \n",
      "Epoch 83/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0414 - acc: 0.9889     \n",
      "Epoch 84/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0605 - acc: 0.9848     \n",
      "Epoch 85/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0581 - acc: 0.9835     \n",
      "Epoch 86/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0527 - acc: 0.9855     \n",
      "Epoch 87/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0436 - acc: 0.9882     \n",
      "Epoch 88/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0532 - acc: 0.9869     \n",
      "Epoch 89/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0583 - acc: 0.9815     \n",
      "Epoch 90/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0949 - acc: 0.9731     \n",
      "Epoch 91/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0795 - acc: 0.9768     \n",
      "Epoch 92/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0586 - acc: 0.9815     \n",
      "Epoch 93/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0549 - acc: 0.9848     \n",
      "Epoch 94/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0458 - acc: 0.9889     \n",
      "Epoch 95/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0422 - acc: 0.9889     \n",
      "Epoch 96/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0501 - acc: 0.9869     \n",
      "Epoch 97/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0470 - acc: 0.9862     \n",
      "Epoch 98/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0475 - acc: 0.9879     \n",
      "Epoch 99/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0481 - acc: 0.9865     \n",
      "Epoch 100/100\n",
      "2970/2970 [==============================] - 0s - loss: 0.0472 - acc: 0.9862     \n",
      "2970/2970 [==============================] - 0s     \n",
      "Standardized: 91.28% (0.27%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2693"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline():\n",
    "\n",
    "    nb_classes = 3\n",
    "\n",
    "    # create model\n",
    "    global model\n",
    "        \n",
    "    if m ==132:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=patchsizeSpaced, activation='relu', name='conv1_0'))\n",
    "        model.add(ZeroPadding2D((2, 2)))\n",
    "        model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "        model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "    if m ==133:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=patchsizeSpaced, activation='relu', name='conv1_0'))\n",
    "#         model.add(ZeroPadding2D((2, 2)))\n",
    "        model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_1'))\n",
    "        model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv2_0'))\n",
    "#         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv2_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv2_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.2))\n",
    "        \n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv3_0'))\n",
    "#         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv3_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv3_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# np.random.seed(seed)\n",
    "estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, nb_epoch=100,\n",
    "                                          batch_size=512, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(y=y_data, n_folds=2, shuffle=True)#, random_state=seed)\n",
    "if not conv1d and dimOrdering == 'th':\n",
    "    X_data = np.swapaxes(X_data_,1,3)\n",
    "    X_data = np.swapaxes(X_data,2,3)\n",
    "    print(X_data.shape)\n",
    "elif conv1d:\n",
    "    print(X_data_.shape)\n",
    "    X_data = X_data_.reshape((X_data_.shape[0], X_data_.shape[1]* X_data_.shape[2], X_data_.shape[3]))\n",
    "    print(X_data.shape)\n",
    "else:\n",
    "    X_data = X_data_\n",
    "\n",
    "if conv3d:\n",
    "    X_data =  np.expand_dims(X_data, 1)\n",
    "    \n",
    "print(X_data.shape)\n",
    "results = cross_val_score(pipeline,X_data, y_data_binary, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "json_string = model.to_json()\n",
    "model.save_weights('my_model_weights_2d_%d.h5'%m, overwrite=True)\n",
    "open('my_model_architecture%d.json'%m, 'w').write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "(60, 50, 90)\n",
      "[10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# we load a test case and the model\n",
    "\n",
    "# model = model_from_json(open('my_model_architecture%d.json'%m).read())\n",
    "# model.load_weights('my_model_weights_2d_%d.h5'%m)\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "print(data_spacing)\n",
    "nrrdData = nrrd.read(USERPATH + '/preprocessed_data/LabelMaps_%.2f-%.2f-%.2f/064/case.nrrd'%(tuple(data_spacing)))\n",
    "im = nrrdData[0]\n",
    "# im = im[100//data_spacing[0]:160//data_spacing[0],80//data_spacing[1]:130//data_spacing[1],70//data_spacing[2]:160//data_spacing[2]]\n",
    "im = im[100:160,80:130,70:160]\n",
    "s = im.shape\n",
    "print(s)\n",
    "print(patchsizeSpaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pyprind\n",
    "# import sys\n",
    "# def findtips(N):\n",
    "#     '''\n",
    "#     Find the tip in the image by computing testing patches at every voxel position\n",
    "#     TODO: make this method more efficient\n",
    "#     '''\n",
    "#     p0, p1, p2 = patchsize\n",
    "#     xmiddle = s[0]//2\n",
    "#     ymiddle = s[1]//2\n",
    "#     zmiddle = s[2]//2\n",
    "    \n",
    "#     x0= xmiddle - xmiddle//N\n",
    "#     y0= ymiddle - ymiddle//N\n",
    "#     z0= zmiddle - zmiddle//N\n",
    "    \n",
    "#     xe= xmiddle + xmiddle//N\n",
    "#     ye= ymiddle + ymiddle//N\n",
    "#     ze= zmiddle + zmiddle//N\n",
    "    \n",
    "#     tips = []\n",
    "#     bar = pyprind.ProgBar(xmiddle//N*2, title='Find_tip', stream=sys.stdout)\n",
    "#     for xi in range(x0, xe-p0):\n",
    "#         for yi in range(y0, ye-p1):\n",
    "#             vols = [im[xi:xi+p0,yi:yi+p1,zi:zi+p2] for zi in range(z0,ze-p2)]\n",
    "#             # we normalize the data (centered on mean 0 and rescaled in function of the STD)\n",
    "#             volnorm = [ x-np.mean(x) for x in vols]\n",
    "#             volnorm2 = [x/np.std(x) for x in volnorm]\n",
    "#             cube = np.array(volnorm2)\n",
    "#             cube = np.swapaxes(cube, 1,3)\n",
    "# #             cube = np.swapaxes(cube, 2,3)\n",
    "#             if conv3d:\n",
    "#                 cube = np.expand_dims(cube,1)\n",
    "#             res = model.predict_proba(cube, batch_size=ze-p2-z0, verbose=False)\n",
    "#             indices = np.where(res[:,0]==1)\n",
    "#             # we add the coordinates of the center voxel of the patches that tested positive\n",
    "#             for z in indices[0]:\n",
    "#                 tips.append([xi+p0/2,yi+p1/2,z0+p2/2+z])\n",
    "#         bar.update()\n",
    "#     return tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import sys\n",
    "def gettips(N):\n",
    "    '''\n",
    "    Find the tip in the image by computing testing patches at every voxel position\n",
    "    TODO: make this method more efficient\n",
    "    '''\n",
    "    p0, p1, p2 = patchsizeSpaced\n",
    "    x0, y0, z0 = 0,0,0\n",
    "    xe, ye, ze = s\n",
    "    \n",
    "    tips = []\n",
    "    bar = pyprind.ProgBar(s[0], title='Find_tip', stream=sys.stdout)\n",
    "    res = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            vols = [im[xi:xi+p0,yi:yi+p1,zi:zi+p2] for zi in range(z0,ze-p2)]\n",
    "            # we normalize the data (centered on mean 0 and rescaled in function of the STD)\n",
    "            volnorm = vols - np.mean(vols)\n",
    "            volnorm2 = volnorm/np.std(volnorm)\n",
    "            cube = np.array(volnorm2)\n",
    "            if not conv1d and dimOrdering == 'th':\n",
    "                cube = np.swapaxes(cube, 1,3)\n",
    "            if conv3d:\n",
    "                cube = np.expand_dims(cube,1)\n",
    "            if conv1d:\n",
    "                cube = cube.reshape(cube.shape[0], cube.shape[1]*cube.shape[2],cube.shape[3])\n",
    "                \n",
    "            res.append(model.predict_proba(cube, batch_size=ze-p2-z0, verbose=False))\n",
    "        bar.update()\n",
    "    return np.array(res)\n",
    "\n",
    "def findtips(res, prob):\n",
    "    N=1\n",
    "    p0, p1, p2 = patchsizeSpaced\n",
    "    \n",
    "    x0, y0, z0 = 0,0,0\n",
    "    xe, ye, ze = s\n",
    "    \n",
    "    i = -1\n",
    "    tips = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            i+=1\n",
    "            indices = np.where(res[i][:,0]>=prob)\n",
    "            # we add the coordinates of the center voxel of the patches that tested positive\n",
    "            for z in indices[0]:\n",
    "                tips.append([xi+p0/2, yi+p1/2, z0+p2/2+z])\n",
    "    return tips\n",
    "\n",
    "def findtips3classes(res, prob, cat):\n",
    "    N=1\n",
    "    res = res[:,:,cat]\n",
    "    p0, p1, p2 = patchsizeSpaced\n",
    "    \n",
    "    x0, y0, z0 = 0,0,0\n",
    "    xe, ye, ze = s\n",
    "    \n",
    "    i = -1\n",
    "    tips = []\n",
    "    for xi in range(x0, xe-p0-1):\n",
    "        for yi in range(y0, ye-p1-1):\n",
    "            i+=1\n",
    "            indices = np.where(res[i][:]>=prob)\n",
    "            # we add the coordinates of the center voxel of the patches that tested positive\n",
    "            for z in indices[0]:\n",
    "                tips.append([xi+p0/2, yi+p1/2, z0+p2/2+z])\n",
    "\n",
    "    return tips\n",
    "\n",
    "def findtips3classes2(res, prob):\n",
    "    N=1\n",
    "    res = (res[:,:,2] + res[:,:,1])/2\n",
    "    p0, p1, p2 = patchsizeSpaced\n",
    "\n",
    "    x0, y0, z0 = 0,0,0\n",
    "    xe, ye, ze = s\n",
    "    \n",
    "    i = -1\n",
    "    tips = []\n",
    "    for xi in range(x0, xe-p0):\n",
    "        for yi in range(y0, ye-p1):\n",
    "            i+=1\n",
    "            indices = np.where(res[i][:]>=prob)\n",
    "            # we add the coordinates of the center voxel of the patches that tested positive\n",
    "            for z in indices[0]:\n",
    "                tips.append([xi+p0/2, yi+p1/2, z0+p2/2+z])\n",
    "    return tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10]\n",
      "Find_tip\n",
      "0%                          100%\n",
      "[########################      ] | ETA: 00:00:02"
     ]
    }
   ],
   "source": [
    "# find the tips for patches with size p\n",
    "print(patchsizeSpaced)\n",
    "pred=gettips(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 80, 3)\n",
      "2000\n",
      "[[ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.16 ...,  0.    0.    0.  ]\n",
      " ..., \n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.set_printoptions(precision=2)\n",
    "pred [ pred < 0.1] = 0\n",
    "print(pred.shape)\n",
    "print(len(pred[:,:,1]))\n",
    "print(pred[:,:,1])\n",
    "# res = findtips(pred, 1)\n",
    "res = findtips3classes(pred, 1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.0, 33.0, 18.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of a labelmap from the voxel that tested positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(im.shape)\n",
    "for coord in res:\n",
    "    mask[int(coord[0]),int(coord[1]),int(coord[2])]=1.0\n",
    "nrrd.write('mask%d.nrrd'%m, mask)\n",
    "nrrd.write('im%d.nrrd'%m, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd2680a5f28>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAADyCAYAAABQ+fHRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njGnAN03GGGOMMQ34pskYY4wxpoH/D6unHrASG714AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2680bb160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "# We display one axial slice\n",
    "Z = 18\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow((np.clip(mask[:,:,Z]*255+im[:,:,Z]/2,a_min=0,a_max=200)).transpose(),  cmap='gray', interpolation='nearest')\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.imshow(im[:,:,Z].transpose(), cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     if m ==7:\n",
    "#         model = Sequential()\n",
    "\n",
    "#         model.add(Convolution2D(10, 10, 2, border_mode='same',\n",
    "#                                 input_shape=(10,10,10)))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(10, 3, 3))\n",
    "#         model.add(Activation('relu'))\n",
    "#         # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#         model.add(Dropout(0.1))\n",
    "\n",
    "#         model.add(Convolution2D(40, 5, 3, border_mode='same' ))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(40, 5, 3, border_mode='same'))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(40, 5, 3))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#         model.add(Dropout(0.1))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "\n",
    "#     if m == 11:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same',\n",
    "#                                 batch_input_shape=(10, 10, 10)))\n",
    "#         # model.add(ZeroPadding2D((1, 1), batch_input_shape=(1, 3, 10, 10)))\n",
    "#         model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "#         model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "#         model.add(Flatten(input_shape=(512,3,3)))\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "\n",
    "#     if m ==13:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=(10,10,10), activation='relu', name='conv1_0'))\n",
    "# #         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(200, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(100, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "#     if m ==132:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=(10,10,10), activation='relu', name='conv1_0'))\n",
    "# #         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(200, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(100, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "#     if m ==132:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', input_shape=(10,10,10), activation='relu', name='conv1_0'))\n",
    "# #         model.add(ZeroPadding2D((2, 2)))\n",
    "#         model.add(Convolution2D(10, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "#         model.add(Convolution2D(10, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(200, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(100, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "#     if m ==14:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution2D(20, 10, 10, border_mode='same', input_shape=(10,10,20), activation='relu', name='conv1_0'))\n",
    "#         model.add(Convolution2D(20, 5, 5, border_mode='same', activation='relu', name='conv1_1'))\n",
    "#         model.add(Convolution2D(20, 10, 10, border_mode='same', activation='relu', name='conv1_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "        \n",
    "#         model.add(Convolution2D(20, 10, 10, border_mode='same', input_shape=(10,10,20), activation='relu', name='conv2_0'))\n",
    "#         model.add(Convolution2D(20, 5, 5, border_mode='same', activation='relu', name='conv2_1'))\n",
    "#         model.add(Convolution2D(20, 10, 10, border_mode='same', activation='relu', name='conv2_2'))\n",
    "#         model.add(MaxPooling2D((4,4), strides=(1,1)))\n",
    "#         model.add(Dropout(0.5))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(200, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(100, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "        \n",
    "        \n",
    "#     if m ==15:\n",
    "#         model = Sequential()\n",
    "\n",
    "#         model.add(Convolution2D(100,2,2, border_mode='same', \n",
    "#                                 input_shape=(20,10,10)))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution2D(50,2,2))\n",
    "# #         model.add(Activation('relu'))\n",
    "# #         model.add(Convolution2D(60,4,4))\n",
    "# #         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#         model.add(Dropout(0.25))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "    \n",
    "#     if m == 16:\n",
    "#         model = Sequential()\n",
    "\n",
    "#         model.add(Convolution3D(20,9,9,18, border_mode='same',\n",
    "#                                 input_shape=(1,10,10,20)))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Convolution3D(20,9,9,19))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# #         model.add(Dropout(0.25))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(480))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(nb_classes))\n",
    "#         model.add(Activation('sigmoid'))\n",
    "        \n",
    "#     if m ==18:\n",
    "#         model = Sequential()\n",
    "\n",
    "#         model.add(ZeroPadding2D((1,1),input_shape=(20,10,10)))\n",
    "#         model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "#         model.add(ZeroPadding2D((1,1)))\n",
    "#         model.add(Convolution2D(512, 2, 2, activation='relu'))\n",
    "#         model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(4096, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(4096, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        \n",
    "#     if m ==20:\n",
    "#         model = Sequential()\n",
    "#         model.add(Convolution1D(100,10, activation='relu', input_shape=(100,10)))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Convolution1D(100,10, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Convolution1D(100,10, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(Convolution1D(100,10, activation='relu'))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         model.add(MaxPooling1D((5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
